\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{minted}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage[hyperfootnotes=true]{hyperref}
\begin{document}

\title{Nata Overview}
\author{Jonathan Leaver}
\date{\today}

\maketitle
\thispagestyle{empty}
\tableofcontents

\clearpage
\pagenumbering{arabic}


\clearpage
\section{Finite State Machines}

Think of a finite state machine in the context of many family board games.  Usually, everyone sits around a table, and on the table is a game map of circles and arrows.  Each person in the family has a token that they place inside one of the circles on the map to show where they are.  This position represents the \mintinline{fsharp}{State} that each player is in.  Outbound from that circle are a number of arrows that represent the places the player can go (often only if certain conditions are met).  As events happen during the game, these act as an \mintinline{fsharp}{Input} to allow the player to move to a new position - a different \mintinline{fsharp}{State}.  For example, rolling some dice or drawing a card allows the player to move to a new circle (hopefully one closer to the goal).

\subsection{Functional Definition}

If we wanted to model each player's unique strategy, we might define a function in F\# corresponding to the following signature:

\begin{minted}{fsharp}
    type Strategy = State -> Input -> State
\end{minted}

In essence, the player's strategy first depends on what \mintinline{fsharp}{State} they're in.  If they're at the start, they will respond to a roll of the dice differently than if they're in a difficult place on the map. Then, once the state has been established, we match with the possible \mintinline{fsharp}{Input} values to determine a new \mintinline{fsharp}{State}.

Suppose we have a simple game where everyone begins in the start state, let's call it \mintinline{fsharp}{State.Start}.  Then the first person to roll a 6, represented as \mintinline{fsharp}{Input.RolledASix}, is the winner.  It's a simple game, and it's exceedingly easy to model the player's strategy:

\begin{minted}{fsharp}
    let strategy : Strategy =
        function
        | State.Start ->
            function
            // if we roll a six at the start, we win
            | Input.RolledASix -> State.Goal 
            // otherwise we wait for the next roll to try again
            | _ -> Start
        | State.Goal ->
            function
            | _ -> Goal // once we've won, we're done
\end{minted}

At this point, we've modeled our first finite state machine.  It contains a set of defined states and inputs, along with the transitions between them.

%\subsection{Event Sourcing}

%\subsection{Actor Systems}
%\mintinline{fsharp}{Nata.Service} builds on this idea.

\clearpage
\section{Service.Consumer}

A consumer service is an entity consisting of some state of its own (e.g. an accumulation), and an index relative to an input channel.  It is defined as:

\begin{minted}{fsharp}
    type Consumer<'StateOrAccumulator,'InputIndex> = {
        State:'StateOrAccumulator
        Index:'InputIndex
    }
\end{minted}

\subsection{Optimistic Concurrency}

\mintinline{fsharp}{Nata.Service} aims to provide reliable, event-based micro-services using optimistic concurrency.  Behind the scenes, this is implemented using the \mintinline{fsharp}{Nata.IO.Competitor<'Data>} capability.  At a minimum, the storage technology used for persisting consumer data needs to support either \mintinline{fsharp}{Competitor} directly, or provide both \mintinline{fsharp}{Nata.IO.ReaderFrom<'Data,'Index>} and \mintinline{fsharp}{Nata.IO.WriterTo<'Data,'Index>}.

Since the input stream's \mintinline{fsharp}{'InputIndex} is recorded by the \mintinline{fsharp}{Consumer} along with the current \mintinline{fsharp}{'StateOrAccumulator}, our service can be stopped and started at will, each time resuming from the last position.  In order to maintain high-availability, multiple instances of the \mintinline{fsharp}{Consumer} can also be started, operating on the same data.  This can enable continuous operation during deployments, as well as potentially provide the shortest possible latency in a real-time system.


\subsection{Module}
\subsubsection{consume - \textit{compete to handle input}}
The simplest primitive related to optimistic concurrency is a consumer that subscribes to some input channel, maintains a checkpoint of where it is in the input stream, and calls a handle function at-least-once for each input.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let checkpoint : Competitor<Consumer<unit,'InputIndex>> =
        Channel.competitor checkpoints
    
    let handle (input:'Input, index:'InputIndex) : unit =
        // cause some side-effect at-least-once,
        // e.g. a sink, an observer, etc.
    
    Consumer.consume subscribeFrom checkpoint handle
    |> Consumer.start
\end{minted}

As you may observe, this \mintinline{fsharp}{Consumer} uses a \mintinline{fsharp}{unit} value for \mintinline{fsharp}{State}.

\subsubsection{consumeEvent}

An overload is available to \mintinline{fsharp}{consume} that exposes \mintinline{fsharp}{Nata.IO.Event<'Input>} metadata from the underlying channel, which might include: date, time, partition key, correlation identifiers, etc.  It differs only in the signature of its handle function:

\begin{minted}{fsharp}
    let handle (input:Event<'Input>, index:'InputIndex) : unit =
        // cause some side-effect at-least-once,
        // e.g. a sink, an observer, logger, etc.
    
    Consumer.consumeEvent subscribeFrom checkpoint handle
    |> Consumer.start
\end{minted}


\subsubsection{fold - \textit{compete for input using the fold pattern}}

Building upon  \mintinline{fsharp}{consume}, \mintinline{fsharp}{Consumer.fold} provides consistency around the consumer's \mintinline{fsharp}{State}, allowing services to evaluate data with a high degree of correctness and reliability. It is similar in character to \mintinline{fsharp}{Seq.fold} and \mintinline{fsharp}{Seq.scan}.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let compete : Competitor<Consumer<'State,'InputIndex>> =
        Channel.competitor output
    let folder (current:'State option) (input:'Input) : 'State =
        // given some current state and an input, update the state

    Consumer.fold subscribeFrom compete folder
    |> Consumer.start
\end{minted}

For example, suppose you want to maintain the total volume of all shares traded for a stock in real time.  To derive this aggregate volume, you might subscribe to an input stream of trades, and add the size of each trade to the total volume accumulated so far.  Moreover, it is essential that each trade contributes precisely once to the total volume, i.e. it is neither skipped nor counted multiple times, just once.

\begin{minted}{fsharp}
    let sumVolume (total:Volume option) { StockTrade.Size=size } =
        match total with
        | None -> size
        | Some total -> total+size

    let trades : Channel<StockTrade,SequenceNumber> = tradesFor "ibm"
    let volume : Channel<Consumer<Volume,SequenceNumber>,_> = tradeVolumeFor "ibm"
        
    Consumer.fold (Channel.subscriberFrom trades) (Channel.competitor volume) sumVolume
    |> Consumer.start
\end{minted}

An important design benefit, demonstrated above, is the ability to decouple our domain logic, i.e. \mintinline{fsharp}{sumVolume}, from the I/O channels and the execution algorithm.  Often, you will want to define the domain types in an external assembly referenced by your micro-services.  This allows you to do extensive unit testing on the domain models themselves, and it also enables you to easily change \textit{how} you run your micro-services, as well as \textit{where} you store your data.

\subsubsection{foldEvent}

An overload of \mintinline{fsharp}{fold}, called \mintinline{fsharp}{foldEvent} is also provided in order to allow for domain functions that accept the \mintinline{fsharp}{Nata.IO.Event<'Input>} data type instead of just \mintinline{fsharp}{'Input}.  All else being equal, the definition above can be altered as follows:

\begin{minted}{fsharp}
    let folder (current:'State option) (input:Event<'Input>) : 'State =
        // given some current state and an input event, update the state
\end{minted}

This overload can be useful if behavior should change depending on event metadata.  If, for example, we wanted to sum volume only for trade events received during market hours, we could simply alter our \mintinline{fsharp}{sumVolume} function to use \mintinline{fsharp}{foldEvent} instead:

\begin{minted}{fsharp}
    let sumVolume (total:Volume option) { Event.Data={ StockTrade.Size=size }; At=at } =
        let size =
            if at.TimeOfDay < TimeSpan.FromHours(9.5) then
                0 // pre-market
            elif at.TimeOfDay > TimeSpan.FromHours(16.) then
                0 // after market
            else size
        match total with
        | None -> size
        | Some total -> total+size
        
    Consumer.foldEvent (Channel.subscriberFrom trades) (Channel.competitor volume) sumVolume
    |> Consumer.start
\end{minted}

\subsubsection{map - \textit{compete for input and apply a projection}}

A projection will map each input into an output value.  When applied to an input stream, it can be used to extract information, derive additional values from it, or even transform and translate that input.  This can be based on established formulas or even rules that are loaded at runtime.

In general, the map function will produce one event on the output channel for each event on the input channel.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let compete : Competitor<Consumer<'Output,'InputIndex>> =
        Channel.competitor output
    let map (input:'Input) : 'Output =
        // given some input, project it into an output value

    Consumer.map subscribeFrom compete map
    |> Consumer.start
\end{minted}

Suppose you're creating a trading strategy that relies on sentiment derived from real-time Twitter posts.  Given that not all posts are in English, it may be useful to apply a projection to the input channel that invokes Google Translate, mapping the results onto a second channel:

\begin{minted}{fsharp}
    let translate { Tweet.Characters=characters } : TranslatedTweet =
        let translation, _ = callGoogleTranslateAPI characters
        { EnglishText=translation }

    let tweets : Channel<Tweet,TweetId> = input
    let translated : Channel<Consumer<TranslatedTweet,TweetId>,_> = output
        
    Consumer.map (Channel.subscriberFrom tweets) (Channel.competitor translated) translate
    |> Consumer.start
\end{minted}

\subsubsection{mapEvent}

An overload of \mintinline{fsharp}{map}, called \mintinline{fsharp}{mapEvent} is also provided.  All else being equal, the definition above can be altered as follows:

\begin{minted}{fsharp}
    let map (input:Event<'Input>) : 'Output =
        // given some input event, project it into an output value
        
    Consumer.mapEvent subscribeFrom compete map
    |> Consumer.start
\end{minted}

\subsubsection{bifold - \textit{compete to fold over two inputs of differing type}}

Similar to \mintinline{fsharp}{Consumer.fold}, it can be especially useful for a consumer service to accept input from two different channels.  Below, these are denoted according to $left$ and $right$. As a result, the next input to be processed is represented as a \mintinline{fsharp}{Choice<'L,'R>} with either a \mintinline{fsharp}{left:'L} value or a \mintinline{fsharp}{right:'R} value.

\begin{minted}{fsharp}
    let l : SubscriberFrom<'L,'IndexL> =
        Channel.subscriberFrom leftInput
    let r : SubscriberFrom<'R,'IndexR> =
        Channel.subscriberFrom rightInput
    let compete : Competitor<Consumer<'State,'IndexL option*'IndexR option>> =
        Channel.competitor output
    let folder (current:'State option) (input:Choice<'L,'R>) : 'State =
        // given some current state and an input (from the left or right), update the state

    Consumer.bifold l r compete folder
    |> Consumer.start
\end{minted}

Note that this is an inherently non-deterministic operation.  Events may arrive on either input channel at any time.  When processing a large backlog of data, the bifold operation may asymmetrically favor the left or right channel.  In real-time operation, generally the first to produce a value is the first to be processed with no requirement that either channel yield an event.  Thus, in practice, it can be safely used to merge events as they happen on either input with no latency.

\subsubsection{bifoldEvent}

As before, a \mintinline{fsharp}{bifoldEvent} overload is available for bifold functions relying on event metadata.  All else being equal, the definition above can be altered as follows:

\begin{minted}{fsharp}
    let folder (current:'State option) (input:Choice<Event<'L>,Event<'R>>) : 'State =
        // given some current state and an input (from the left or right), update the state

    Consumer.bifold l r compete folder
    |> Consumer.start
\end{minted}

\subsubsection{bimap - \textit{compete to project from two inputs of differing type}}

This variant of \mintinline{fsharp}{Consumer.map} accepts input from two different channels (potentially of different types).  These are denoted below as $left$ and $right$.  Correspondingly, each input to be processed is represented as a \mintinline{fsharp}{Choice<'L,'R>} containing either a \mintinline{fsharp}{left:'L} value or a \mintinline{fsharp}{right:'R} value.

\begin{minted}{fsharp}
    let l : SubscriberFrom<'L,'IndexL> =
        Channel.subscriberFrom leftInput
    let r : SubscriberFrom<'R,'IndexR> =
        Channel.subscriberFrom rightInput
    let compete : Competitor<Consumer<'State,'IndexL option*'IndexR option>> =
        Channel.competitor output
    let map (input:Choice<'L,'R>) : 'Output =
        // given an input (from the left or right), project it into an output value

    Consumer.bimap l r compete map
    |> Consumer.start
\end{minted}

As with \mintinline{fsharp}{Consumer.bifold}, this is also a potentially non-deterministic function.  Please refer to the notes for that function to understand their behavioral implications.

\subsubsection{bimapEvent}

Similarly, a \mintinline{fsharp}{bimapEvent} overload is available for bimap functions relying on event metadata.  All else being equal, the definition above can be altered as follows:

\begin{minted}{fsharp}
    let map (input:Choice<Event<'L>,Event<'R>>) : 'Output =
        // given an input event (from the left or right), project it into an output value

    Consumer.bimapEvent l r compete map
    |> Consumer.start
\end{minted}

\subsubsection{multifold - \textit{compete to fold over many inputs of the same type}}

In order to fold over multiple input channels in a reliable way, the \mintinline{fsharp}{'InputIndex} on each channel will need to be recorded.  As a result, it is necessary to be able to identify each of the separate subscriptions.  To accomplish this, we use an arbitrary \mintinline{fsharp}{'SourceId}.  It can be an integer, string, or any other type provided \mintinline{fsharp}{'SourceId} can be used as a key by the \mintinline{fsharp}{FSharp.Collections.Map} datastructure, i.e. it satisfies the  \mintinline{fsharp}{(requires comparison)} constraint.

\begin{minted}{fsharp}
    let subscribersById : Map<'SourceId, SubscriberFrom<'Input,'InputIndex>> =
        [
            for unique_id, input in inputs ->
                unique_id, Channel.subscriberFrom input

        ] |> Map.ofList

    let compete : Competitor<Consumer<'State,Map<'SourceId,'InputIndex>>> =
        Channel.competitor output
    let folder (current:'State option) (input:'Input) : 'State =
        // given some current state and an input, update the state

    Consumer.multifold subscribersById compete folder
    |> Consumer.start
\end{minted}

An additional requirement is that all inputs must have the same type.  If we wanted to fold over three or four channels of differing types using \mintinline{fsharp}{multifold}, a useful strategy is to map each of the inputs into a distinct case of a discriminated union.  For example, suppose that we want to write an algorithmic trading strategy that accepts inputs including market data quotes, trades, orders executions, and user commands:

\begin{minted}{fsharp}
    let inputs : Map<string, SubscriberFrom<Input,'InputIndex>> =
        [
            "quotes",
            Channel.subscriberFrom quotes
            |> SubscriberFrom.mapData Input.Quote

            "trades",
            Channel.subscriberFrom trades
            |> SubscriberFrom.mapData Input.Trade

            "executions",
            Channel.subscriberFrom executions
            |> SubscriberFrom.mapData Input.Execution

            "commands",
            Channel.subscriberFrom commands
            |> SubscriberFrom.mapData Input.Command

        ]
        |> Map.ofList

    let algorithm (current:'State option) = function
        | Input.Quote { Bid=bid; Ask=ask } ->
            // update the state based on a new quote
        | Input.Trade { Price=price; Size=size } ->
            // update the state based on a trade
        | Input.Execution { OrderResult=result } ->
            // update the state based on an order execution
        | Input.Command Command.WorkHarder ->
            // update the state when the trader asks us to work harder
        | Input.Command Command.WorkSmarter ->
            // update the state when the trader asks us to work smarter

    Consumer.multifold inputs compete algorithm
    |> Consumer.start
\end{minted}

In this way, positions on each input channel can be identified using a simple \mintinline{fsharp}{'SourceId} of \mintinline{fsharp}{string}, and the strategy can be written with an easy-to-read finite state machine.

\subsubsection{multifoldEvent}

An overload of \mintinline{fsharp}{multifold} is also available for \mintinline{fsharp}{Nata.IO.Event<'Input>}:

\begin{minted}{fsharp}
    let folder (current:'State option) (input:Event<'Input>) : 'State =
        // given some current state and an input event, update the state

    Consumer.multifoldEvent subscribersById compete folder
    |> Consumer.start
\end{minted}

Since event metadata can be different depending on the input source, the discriminated union strategy for multiple input channels described above should be used with care.  Metadata will accurately reflect the information available from the input source, including any subtle differences among those sources.  For instance, Apache Kafka may include partition information, whereas EventStore would not.

\subsubsection{multimap - \textit{compete to project from many inputs of the same type}}

\begin{minted}{fsharp}
    let subscribersById : Map<'SourceId, SubscriberFrom<'Input,'InputIndex>> =
        [
            for unique_id, input in inputs ->
                unique_id, Channel.subscriberFrom input

        ] |> Map.ofList

    let compete : Competitor<Consumer<'Output,Map<'SourceId,'InputIndex>>> =
        Channel.competitor output
    let map (input:'Input) : 'Output =
        // given an input (from any subscriber), project it into an output value

    Consumer.multimap subscribersById compete map
    |> Consumer.start
\end{minted}

This can be very helpful when you need to simply merge multiple channels together.  For instance, suppose that order executions are received from four different order adapters.  The data is the same type, but we need to merge them together so they can be sent into our reporting database.  In the following example, we use the identity function, \mintinline{fsharp}{id}, to copy the values across without any additional transformation.

\begin{minted}{fsharp}
    let subscribersById : Map<string, SubscriberFrom<'Input,'InputIndex>> =
        [   "gemini", Channel.subscriberFrom geminiExecutions
            "hitbtc", Channel.subscriberFrom hitbtcExecutions
            "kraken", Channel.subscriberFrom krakenExecutions
            "bitfinex", Channel.subscriberFrom bitfinexExecutions
        ] |> Map.ofList

    let compete : Competitor<Consumer<'Input,Map<string,'InputIndex>>> =
        Channel.competitor output

    Consumer.multimap subscribersById compete id // use id to simply merge 1-to-1
    |> Consumer.start
\end{minted}

\subsubsection{multimapEvent}

A \mintinline{fsharp}{Consumer.multimap} overload is also available for \mintinline{fsharp}{Nata.IO.Event<'Input>}:

\begin{minted}{fsharp}
    let folder (input:Event<'Input>) : 'Output =
        // given an input event (from any subscriber), project it into an output value

    Consumer.multifoldEvent subscribersById compete folder
    |> Consumer.start
\end{minted}

\subsubsection{partition - \textit{compete to partition input to an output channel}}

Partition will "fan-out" events from an input channel onto a specific output channel according to the given partitioning function.  All data on the published output channels must originate from this input, since output consumers are \textit{only} written if their last input index is less than the current index of the input subscription.  This helps to guarantee the correct ordering of events within a partition.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let checkpoint : Competitor<Consumer<unit,'InputIndex>> =
        Channel.competitor output
    
    let partition (input:'Input) :
        (ReaderFrom<Consumer<'Input,'InputIndex>,'OutputIndex>
         * WriterTo<Consumer<'Input,'InputIndex>,'OutputIndex>) =
        
        // returns the readerFrom and writerTo the output channel
        // based on any characteristic of the input
        selectOutputFor input
        
    Consumer.partition subscribeFrom checkpoint partition
    |> Consumer.start
\end{minted}

Suppose we want to partition even numbers to one stream, and odd numbers to another.  We might use partition as follows:

\begin{minted}{fsharp}
    let odd = Channel.readerFrom odds, Channel.writerTo odds
    let even = Channel.readerFrom evens, Channel.writerTo evens
        
    let partition (input:int) =
        if input % 2 = 0 then even else odd
        
    Consumer.partition subscribeFrom checkpoint partition
\end{minted}

\subsubsection{partitionEvent}

Moreover, \mintinline{fsharp}{Consumer.partitionEvent} allows for partitioning based on the underlying \mintinline{fsharp}{Nata.IO.Event<'Input>} metadata:

\begin{minted}{fsharp}
    // partition events into separate morning(AM) and afternoon(PM) channels:
    let partition { Event.At=at } =
        if at.TimeOfDay < TimeSpan.FromHours 12. then AM else PM

    Consumer.partitionEvent subscribeFrom checkpoint partition
    |> Consumer.start
\end{minted}

\subsubsection{distribute - \textit{compete to distribute input among output channels}}

\mintinline{fsharp}{Consumer.distribute} elaborates upon \mintinline{fsharp}{partition} by permitting multiple output channels for an input.  Additionally, it also allows for an empty list of output channels to be returned, in which case the input is effectively skipped, although the checkpoint will report it as processed.

As with partition, all data published on the selected outputs must originate from this input channel, since input indexes are used to guarantee that an output is written precisely once.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let checkpoint : Competitor<Consumer<unit,'InputIndex>> =
        Channel.competitor output
    
    let distribute (input:'Input) :
        (ReaderFrom<Consumer<'Output,'InputIndex>,'OutputIndex>
         * WriterTo<Consumer<'Output,'InputIndex>,'OutputIndex>
         * Merge<'Input,'Output>) list =
        
        // returns a list of readerFrom+writerTo+merge for output channels
        // based on any characteristic of the input
        selectOutputsFor input
        
    Consumer.distribute subscribeFrom checkpoint distribute
    |> Consumer.start
\end{minted}

An additional subtlety of \mintinline{fsharp}{distribute} is that it requires a merge function to be returned along with each output channel selected.  \mintinline{fsharp}{Merge<'Input,'Output>} defines how the operation should merge the new input into the selected output channel.  For instance, returning \mintinline{fsharp}{Merge.usingInput} will simply use the new input value.  This can be adjusted during selection by providing a \mintinline{fsharp}{Merge.using x} where $x$ is some determined value of the \mintinline{fsharp}{'Input} type.

\subsubsection{distributeEvent}

Using the \mintinline{fsharp}{Consumer.distributeEvent} overload only requires a slight change to the distribution function:

\begin{minted}{fsharp}
    let distribute (input:Event<'Input>) = // selection is exactly as before
        
    Consumer.distributeEvent subscribeFrom checkpoint distribute
    |> Consumer.start
\end{minted}

\subsubsection{multipartition - \textit{compete to partition inputs among output channels}}

\mintinline{fsharp}{Consumer.multipartition}, \mintinline{fsharp}{multipartitionEvent}, \mintinline{fsharp}{multidistribute}, and \mintinline{fsharp}{multidistributeEvent} differ in a very important way from their regular counterparts.  In addition to performing a "fan-out" from one input channel onto many, they can also perform "fan-in" where multiple services publish to the same output.

The difference is most notable in the representation of the consumer index on the output channels. Instead of using \mintinline{fsharp}{Consumer<'Output,'InputIndex>}, they now use \mintinline{fsharp}{Consumer<'Output,Map<'SourceId,'InputIndex>>}.  This allows us to provide a unique \mintinline{fsharp}{'SourceId} for this input to differentiate it from others. One important caveat, however, is that the input index needs to be the same data type across all channels.  If you need to mix input source technologies (such as EventHub which uses a \mintinline{fsharp}{string} index versus EventStore which uses an \mintinline{fsharp}{int64} index versus Kafka which uses a \mintinline{fsharp}{partition, offset} pair), then it will be necessary to first apply a mapIndex operation to each source (converting their respective positions to and from \mintinline{fsharp}{JsonValue}, for instance).

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let checkpoint : Competitor<Consumer<unit,'InputIndex>> =
        Channel.competitor output
    
    let partition (input:'Input) :
        (ReaderFrom<Consumer<'Input,Map<'SourceId,'InputIndex>>,'OutputIndex>
         * WriterTo<Consumer<'Input,Map<'SourceId,'InputIndex>>,'OutputIndex>) =
        
        // returns the readerFrom and writerTo the output channel
        // based on any characteristic of the input
        selectOutputFor input
        
    Consumer.multipartition subscribeFrom checkpoint sourceId partition
    |> Consumer.start
\end{minted}

\subsubsection{multipartitionEvent}

\begin{minted}{fsharp}
    let partition (input:Event<'Input>) = // selection is exactly as before
    
    Consumer.multipartitionEvent subscribeFrom checkpoint sourceId partition
    |> Consumer.start
\end{minted}

\subsubsection{multidistribute - \textit{compete to distribute inputs among output channels}}

Although more complicated than the other functions of this module, \mintinline{fsharp}{Consumer.multidistribute} is quite possibly the most powerful in terms of implementing sophisticated topologies.  One factor to keep in mind, however, is that these functions will store a mapping from \mintinline{fsharp}{'SourceId} to \mintinline{fsharp}{'InputIndex} in the output channel. If we have a channel for each order in a trading system getting distributed onto an account, the I/O cost to update the account balance will grow as the number of orders increases.

\begin{minted}{fsharp}
    let subscribeFrom : SubscriberFrom<'Input,'InputIndex> =
        Channel.subscriberFrom input
    let checkpoint : Competitor<Consumer<unit,'InputIndex>> =
        Channel.competitor output
    
    let distribute (input:'Input) :
        (ReaderFrom<Consumer<'Output,Map<'SourceId,'InputIndex>>,'OutputIndex>
         * WriterTo<Consumer<'Output,Map<'SourceId,'InputIndex>>,'OutputIndex>
         * Merge<'Input,'Output>) list =
        
        // returns a list of readerFrom+writerTo+merge for output channels
        // based on any characteristic of the input
        selectOutputsFor input
        
    Consumer.multidistribute subscribeFrom checkpoint sourceId distribute
    |> Consumer.start
\end{minted}

\subsubsection{multidistributeEvent}

\begin{minted}{fsharp}
    let distribute (input:Event<'Input>) = // selection is exactly as before
    
    Consumer.multidistributeEvent subscribeFrom checkpoint sourceId distribute
    |> Consumer.start
\end{minted}






% Note: Produce functions are very similar to the partially applied functions used in Nova, such as StagingStore, SkuStore, GroupStore, etc, which result in specialized functions that take an ID and some input event and perform some predetermined behavior (e.g. updating a sku).
% \subsection{Consumer.produce}
%A more sophisticated primitive related to optimistic concurrency is the capability to construct a producer that writes values only when they are newer (by input index) than the existing data.  This construct is especially useful when combined with partial application.
% \subsubsection{Consumer.produceEvent}
%\subsection{Consumer.multiproduce}
% This is much more like 
%\subsubsection{Consumer.multiproduceEvent}

\clearpage
\section{Service.Binding}

In the previous section covering \mintinline{fsharp}{Nata.Service.Consumer}, we introduced some useful ways to construct microservices with very specific semantic guarantees.  When building networks of event-driven microservices on top of that library, it becomes important to streamline the way that channels and domain functions are combined in order to solve problems at real-world scale.  \mintinline{fsharp}{Nata.Service.Binding} makes it possible to snap channels together along with their intermediate domain logic in a way that maximizes inference and type safety while allowing a greater focus on the system topology.

\subsection{Module}

\begin{itemize}
    \item Prerequisites from \mintinline{fsharp}{Nata.IO}:
    \begin{itemize}
        \item We need a mechanism to obtain a channel that supports either one of:
        \begin{itemize}
            \item \mintinline{fsharp}{Competitor<'Data>}
            \item \mintinline{fsharp}{ReaderFrom<'Data,'Index>} and \mintinline{fsharp}{WriterTo<'Data,'Index>}
        \end{itemize}
        \item For these examples, consider using any of the following:
        \begin{itemize}
            \item \mintinline{fsharp}{Memory.Stream}
            \item \mintinline{fsharp}{File.Stream}
            \item \mintinline{fsharp}{EventStore.Stream}
        \end{itemize}
    \end{itemize}
\end{itemize}

Given such a source, let's assume the following type signature.  We mark it inline to allow for different types of  \mintinline{fsharp}{'Data}.  In the case of \mintinline{fsharp}{Memory.Stream}, the index is always \mintinline{fsharp}{int64}, so we will use '\mintinline{fsharp}{_}' to infer this in subsequent examples:

\begin{minted}{fsharp}
    let inline channelFor (name:ChannelName) : Channel<'Data,_> =
        Nata.IO.Memory.Stream.create name
\end{minted}

\subsubsection{fold}

Let's suppose we have an input channel of integers and we want to track the sum of all integers seen so far.  We can bind two channels and the sum function together very easily:

\begin{minted}{fsharp}
    let input : Channel<int,_> = channelFor "input"
    let sums : Channel<Consumer<int,_>,_> = channelFor "sums"

    let sum : int option -> int -> int =
        Option.defaultValue 0 >> fun total x -> total + x
    
    let binding : seq<Consumer<int,_>> =
        input
        |> Binding.fold sum sums
\end{minted}

\subsubsection{start}

Having created the binding from input to output, we learn something important about the evaluation of microservices in \mintinline{fsharp}{Nata.Service}: that bindings themselves are sequences.  We can force evaluation of the binding using \mintinline{fsharp}{Seq.iter ignore}.  An alternative is to pipe the binding into \mintinline{fsharp}{Binding.start : seq<'a> -> unit} which will do the same thing. 

\begin{minted}{fsharp}
    binding
    |> Binding.start
\end{minted}

\subsubsection{startAsync}

In a script or service where you'd like to create multiple bindings and start them on the thread pool, you can use \mintinline{fsharp}{Binding.startAsync : seq<'a> -> unit} instead, for example:

\begin{minted}{fsharp}
    input
    |> Binding.fold sum sums
    |> Binding.startAsync
\end{minted}

This comparatively simple execution mechanism opens the door for a host of powerful capabilities, such as custom supervision and monitoring.

\subsubsection{asInput}

Having created an output \mintinline{fsharp}{Channel<Consumer<int,_>,_>}, we might like to use this channel as an input into a subsequent operation.  This is really very simple:

\begin{minted}{fsharp}
    let sumsAsInput : Channel<int,_> =
        sums
        |> Binding.asInput
\end{minted}

\subsubsection{map}

So when we want to track the sum divided by two, we can map the \mintinline{fsharp}{sums} channel as follows:

\begin{minted}{fsharp}
    let halfSums : Channel<Consumer<int,_>, _> = channelFor "half-sums"

    sums
    |> Binding.asInput
    |> Binding.map (fun x -> x / 2) halfSums
    |> Binding.startAsync
\end{minted}

\subsubsection{bifold}

Next, let's suppose we're watching revenue and expense events in order to determine how much money we've made.  For this example, we start with an initial balance of \mintinline{fsharp}{0m}, and a real-time stream of \mintinline{fsharp}{revenue}, such as cash or checks received from our summer job, and \mintinline{fsharp}{expenses}, such as cash paid for lunch or checks for the rent.

\begin{minted}{fsharp}
    let updateBalance (balance:decimal) = function
        | Choice1Of2 x -> balance+x
        | Choice2Of2 x -> balance-x
    let updateBalanceStartingAtZero =
        Option.defaultValue 0m >> updateBalance

    (channelFor "revenue", channelFor "expenses")
    |> Binding.bifold updateBalanceStartingAtZero (channelFor "balances")
    |> Binding.startAsync
\end{minted}

Here we've started a binding that folds over both streams, adding or removing money from our balance depending on the input channel.

\subsubsection{bimap}

For our next service, we're given channels for \mintinline{fsharp}{purchases} and \mintinline{fsharp}{leases} that contain information we can use to feed a system that estimates demand for products.  As a result, we will extract product name, quantity and price into a \mintinline{fsharp}{transactions} channel that will be used later.

\begin{minted}{fsharp}
    let toTransaction = function
        | Choice1Of2 { ProductPurchased=name
                       PurchasePrice=price
                       Quantity=quantity } ->
            { Transaction.Product=name; Price=decimal price; Quantity=quantity }
        | Choice2Of2 { Name=name
                       LeaseAmount=price } ->
            { Transaction.Product=name; Price=price; Quantity=1 }

    (channelFor "purchases", channelFor "leases")
    |> Binding.bimap toTransaction (channelFor "transactions")
    |> Binding.startAsync
\end{minted}

As you can see, the new \mintinline{fsharp}{transactions} channel will contain key elements from the underlying channels for \mintinline{fsharp}{purchases} and \mintinline{fsharp}{leases} merged into a new record type called \mintinline{fsharp}{Transaction}.

\subsubsection{multifold}

Our smart home system manages each of the 100 watt light bulbs on our property.  We want to text our teenage children when the wattage being consumed exceeds a certain threshold.  Since each device publishes an event to its channel when a light is turned on or off, we should be able to track the total wattage in use.

\begin{minted}{fsharp}
    let updateTotalWattageConsumed (total:int<Watts>) = function
        | TurnedOn -> total + 100<Watts>
        | TurnedOff -> total - 100<Watts>
    let updateTotalWattageConsumedFromZero =
        Option.defaultValue 0<Watts> >> updateTotalWattageConsumed

    let deviceChannels : Map<DeviceId, Channel<DeviceEvent,_>> =
        // from our smart home system

    let totalWattageChannel = channelFor "total-wattage"

    Map.toSeq deviceChannels
    |> Binding.multifold updateTotalWattageConsumedFromZero totalWattageChannel
    |> Binding.startAsync
\end{minted}

From here, it's a simple matter to consume the \mintinline{fsharp}{"total-wattage"} channel and text the kids when too many lights are left on:

\begin{minted}{fsharp}
    let checkpoint =
        Channel.competitor(channelFor "text-alert-checkpoint")
    let subscriberFrom =
        Channel.subscriberFrom(Binding.asInput totalWattageChannel)

    Consumer.consume subscriberFrom checkpoint sendTextMessage
    |> Consumer.startAsync
\end{minted}

\subsubsection{multimap}

Suppose we want to create a signal for our trading system based on how much volume is being traded in the market.  Since \mintinline{fsharp}{multimap} accepts many channels of the same type, we can subscribe to trades for multiple stock symbols and compute the value of each transaction.

\begin{minted}{fsharp}
    let tradeValue = function
        | { Price=price
            Quantity=quantity } -> price * decimal quantity

    let tradeValues = channelFor "trade-values"
    let tradesBySymbol : Map<Symbol, Channel<Trade,_>> =
        // from our market data

    Map.toSeq tradesBySymbol
    |> Binding.multimap tradeValue tradeValues
    |> Binding.startAsync
\end{minted}

\subsubsection{partition}

Having created a channel of trade values, we can partition it according to the transaction size:

\begin{minted}{fsharp}
    let partitionByTradeValue =

        let large = channelFor "large-trade-values"
        let medium = channelFor "medium-trade-values"
        let small = channelFor "small-trade-values"
    
        fun (tradeValue:decimal) ->
            if tradeValue > 10000000.00m then large
            elif tradeValue < 1000.00m then small
            else medium

    let checkpoint =
        channelFor "partition-trade-value-checkpoint"

    tradeValues
    |> Binding.asInput
    |> Binding.partition partitionByTradeValue checkpoint
    |> Binding.startAsync
\end{minted}

As a result, trades valued greater than 10 million dollars are partitioned separately from trades less than 1 thousand dollars as well as those trades of only moderate value.

\subsubsection{distribute}

In the next example, we accept a stream of integers, and we need to place each integer on streams according to its prime factors.  For instance, $502978$ will need to be placed on channels $\{ 2, 7, 37, 971 \}$.

\begin{minted}{fsharp}
    // choose any fun F# prime factorization algorithm:
    let primeFactorsOf : int -> int Set =
        let rec loop acc x i = 
            if i = x then Set.add x acc
            elif i % x = 0 then loop (Set.add x acc) x (i / x)
            else loop acc (x + 1) i
        loop Set.empty 2

    // let's also keep the prime-factor channels around
    let channelForPrime : int -> Channel<_,_> =
        let lookup = new Dictionary<_,_>()
        fun id ->
            if not(lookup.ContainsKey(id)) then
                lookup.[id] <- channelFor(sprintf "prime-factor-%d" id)
            lookup.[id]

    // based on the prime factors, merge the integer into each channel
    let distributePrimeFactors =
        primeFactorsOf
        >> Seq.map (fun x -> Merge.using x, channelForPrime x)
        >> Seq.toList
    
    let input = channelFor "input-numbers"
    let checkpoint = channelFor "prime-factor-checkpoint"

    input
    |> Binding.distribute distributePrimeFactors checkpoint
    |> Binding.startAsync
\end{minted}

\subsubsection{multipartition}

We receive orders from multiple channels, such as online and in-store.  Each product can be manufactured at one of our factories.  Let's route orders, as a \mintinline{fsharp}{WorkUnit}, to one of those factories using a partitioning algorithm.  In this case, the offset for each order channel is tracked according to the service \mintinline{fsharp}{id} that produced it.

\begin{minted}{fsharp}
    let orderChannels =
        [ "online", channelFor "online-orders"
          "in-store", channelFor "in-store-orders" ]

    let factories =
        [ channelFor "factory-0"
          channelFor "factory-1"
          channelFor "factory-2" ]

    let partition { WorkUnit.Id=x } =
        factories.[ x.GetHashCode() % factories.Length ]
    
    let checkpoint =
        sprintf "%s-order-partition-checkpoint"
        >> channelFor

    for id, orderChannel in orderChannels do
        orderChannel
        |> Binding.multipartition id partition (checkpoint id)
        |> Binding.startAsync
\end{minted}

As you see, we can bind multiple input channels to multiple output channels according to a partitioning algorithm - in this case, a very simple one. 

\subsubsection{multidistribute}

When we upload photos to social media, we might want to distribute those to the news feed for each of our friends.  In the following example, we accept a photo (consisting of a \mintinline{fsharp}{Photographer} and \mintinline{fsharp}{Link} among other fields.  For each photo, we obtain list of channels for this photographer and share the link.

\begin{minted}{fsharp}
    let friendsOf (name:Name) : Channel<_,_> list =
        // return channels for this person's friend list

    let postPhotoFor { Photographer=name
                       Link=link } =
        [   let sharedPhoto = SharedContent.Photo link
            for friendChannel in friendsOf name ->
                Merge.using sharedPhoto, friendChannel ]

    let photoUploadChannel = channelFor "photo-uploads"
    let id, checkpoint =
        "shared-photos", channelFor "photo-share-checkpoint"
    
    photoUploadChannel
    |> Binding.multidistribute id postPhotoFor checkpoint
    |> Binding.startAsync
\end{minted}

First, each friend's feed can accept \mintinline{fsharp}{SharedContent} from a variety of different sources in addition to our \mintinline{fsharp}{"shared-photos"} service.  Additionally, the \mintinline{fsharp}{Merge.using} operation allows us to transform our input data for our output channels.  We'll cover the \mintinline{fsharp}{Merge} and \mintinline{fsharp}{MergeEvent} modules next.

\subsubsection{reset}

Finally, it may be necessary to reset a service to an alternate position or state.  For the previous example, let's obtain the index of \mintinline{fsharp}{Position.Start} in the input channel, and reset the checkpoint.  Remember, the state of a checkpoint channel is unit.

\begin{minted}{fsharp}
    Channel.indexer photoUploadChannel Position.Start
    |> Binding.reset () checkpoint  
\end{minted}

%Two universal strategies are provided out of the box, one for 
\subsection{Service.Merge}

When using \mintinline{fsharp}{distribute} and \mintinline{fsharp}{multidistribute} from either \mintinline{fsharp}{Service.Consumer} or \mintinline{fsharp}{Service.Binding}, merge strategies can be provided.  As a result, two convenience functions are available:

\begin{description}
    \item[usingInput] places the input value directly on the target channel.
    \item[using] accepts an alternative value corresponding to the channel.
\end{description}

You can also supply a custom implementation that accepts the current value, the incoming value, and a strategy for resolving them, of type \mintinline{fsharp}{'State option->'Input->'State}.  In both cases, the type of the merge value will need to match the \mintinline{fsharp}{'State} of the channel receiving it.

\subsection{Service.MergeEvent}

For \mintinline{fsharp}{Consumer.distributeEvent} and \mintinline{fsharp}{Consumer.multidistributeEvent}, merge functions are also provided that use \mintinline{fsharp}{Nata.IO.Event<'Input>}:

\begin{description}
    \item[usingInput] places the input event value directly on the target channel
    \item[using] accepts an alternate event value corresponding to the channel.
\end{description}

As before, a custom merge strategy of \mintinline{fsharp}{'State option->Event<'Input>->'State} can be also provided, where \mintinline{fsharp}{'State} matches the receiving channel.

\clearpage
\section{Service.Hub.Snapshot}
\subsection{Module}

A snapshot hub makes a single subscription to an input channel.  It's useful when subscriptions are expensive, and when consumers lagging under heavy load can be satisfied with the most recent events from the subscription.

\subsubsection{create}

\begin{minted}{fsharp}
    // create a hub and subscribe it to a channel
    let connectToHubFor (channel:Channel<'Data,'Index>) : unit->seq<Event<'Data>> =
    
        let subscribeFrom : SubscriberFrom<'Data,'Index> =
            Channel.subscriberFrom channel
    
        Hub.Snapshot.create subscribeFrom
\end{minted}

For example, you might use this to provide the latest quote from a streaming ticker of stock prices.  A connection to the market data feed is potentially expensive, and a client will prefer the most recent snapshot if there are several in the stream.  Consider the following example:

\begin{minted}{fsharp}
    let ibm : StockSymbol = "IBM"
    let quotes : Channel<StockQuote,LiveFeedIndex> = feedFor ibm

    let connectToHub : unit->seq<Event<StockQuote>> =
        quotes
        |> Channel.subscriberFrom
        |> Hub.Snapshot.create

    [
      // Consumer #1: processes quotes after some initial lag
      async {
        do! Async.Sleep(10)
        for { Data=quote } in connectToHub() do
          consume quote 
      }
      // Consumer #2: incurs heavy lag while processing each quote
      async {
        for { Data=quote } in connectToHub() do
          do! Async.Sleep(500)
          consume quote
      }
    ]
    |> Async.Parallel
    |> Async.RunSynchronously
\end{minted}

Suppose the underlying quote stream contains the sequence $\{q_1..q_5\}$. In this example, the first consumer might observe the sequence $\{q_2,q_3,q_4,q_5\}$, while the second consumer might see $\{q_1,q_5\}$. Both consumers will always receive the latest snapshot $q_5$ in the stream.  However, the first consumer was late to start and missed $q_1$, whereas the second consumer incurred a sizeable lag processing $q_1$ and next observed $q_5$.

A snapshot hub retains the most recent event, and provides that event (if available) to a new consumer. As a result, memory consumption during high-latency processing or heavy load is minimized.  Additionally, note that event aggregation is not provided by the snapshot hub: if aggregation is required, you should apply that step to the input channel using something like \mintinline{fsharp}{fold}.

\clearpage
\section{Nata.Core}

\subsection{Overview}

\noindent \mintinline{fsharp}{Nata.Core} gathers small, reusable building blocks that make day-to-day functional programming more expressive and safe. 
They emphasize predictable semantics, ergonomic pipelining, and minimal ceremony. 
You will find tuple helpers for shaping data, sequence operators for time-series and merging, option/null handling, numeric and string utilities, and small bridges between \mintinline{fsharp}{Async} and \mintinline{fsharp}{Task}.

\subsubsection{Design goals}
\begin{itemize}
  \item Ergonomic piping: helpers like \mintinline{fsharp}{swap}, \mintinline{fsharp}{mapFst}, and \mintinline{fsharp}{mapSnd} keep pipelines readable.
  \item Safety by default: null- and exception-safe adapters (\mintinline{fsharp}{Null.toOption}, \mintinline{fsharp}{Option.tryFunction}) reduce accidental partiality.
  \item Time-series friendly: \mintinline{fsharp}{Seq.mergeBy}, \mintinline{fsharp}{Seq.changesBy}, and \mintinline{fsharp}{Seq.delta} focus on ordered streams.
  \item Pragmatic interop: small shims for parsing and clamping (\mintinline{fsharp}{*.ofString}, \mintinline{fsharp}{*.between}) and for \mintinline{fsharp}{Task}<->\mintinline{fsharp}{Async}.
\end{itemize}

\subsubsection{Guided examples}

\paragraph{Tuples and pipelining}
Shaping events often starts with tuples. Use \mintinline{fsharp}{mapFst} and \mintinline{fsharp}{mapSnd} to transform one side without touching the other.
\begin{minted}{fsharp}
    // unpack (Event * Index) into (Data * Index)
    let unpack : (Event<'a>*'i) -> ('a*'i) =
        mapFst Event.data

    // look up a sequence of keys via a map, left-to-right
    let tryFindAll (m:Map<'k,'v>) (keys:seq<'k>) : seq<'v> =
        keys
        |> Seq.choose (m |> swap Map.tryFind)
\end{minted}

\paragraph{Time-series: changes and deltas}
Filter out consecutive duplicates or compute first-order differences with \mintinline{fsharp}{Seq.changesBy} and \mintinline{fsharp}{Seq.delta}.
\begin{minted}{fsharp}
    // keep only changes in closing price
    let changedCloses : seq<decimal> =
        closes |> Seq.changesBy id

    // turn a stream of values into pairwise deltas
    // e.g. [10m; 12m; 11m] -> [2m; -1m]
    let deltas : seq<decimal> =
        closes
        |> Seq.delta
        |> Seq.choose (fun (last,next) -> last |> Option.map (fun l -> next - l))
\end{minted}

\paragraph{Merging ordered streams}
When two feeds are independently ordered (e.g., by timestamp), \mintinline{fsharp}{Seq.mergeBy} preserves overall order without re-sorting.
\begin{minted}{fsharp}
    // left and right are (Event * timestamp) streams
    let mergedData : seq<'a> =
        Seq.mergeBy snd left right
        |> Seq.mapFst Event.data
        |> Seq.map fst  // drop timestamps if desired
\end{minted}

\paragraph{Options, nulls, and exceptions}
Prefer options to represent absence. Convert nulls, coalesce fallbacks, and sink exceptions into \mintinline{fsharp}{None} when its appropriate.
\begin{minted}{fsharp}
    let bigOrder : int option =
        qty |> Option.whenTrue (fun q -> q > 1000)

    let preferred : string option =
        someNullableString |> Null.toOption

    let safeParsed : int option =
        "42" |> Option.tryFunction Int32.Parse

    let chosen : decimal =
        primary
        |> Option.coalesce backup
        |> Option.defaultValue 0m
\end{minted}

\paragraph{Parsing and clamping}
Small helpers make validation pipelines explicit and testable.
\begin{minted}{fsharp}
    let cappedRatio : decimal option =
        input
        |> Decimal.ofString                 // string -> decimal option
        |> Option.map (Decimal.between (0m, 1m)) // clamp into [0,1]
\end{minted}

\paragraph{Tasks and async}
Bridge \mintinline{fsharp}{Task}-based APIs into \mintinline{fsharp}{Async}, or wait safely for results in controlled places.
\begin{minted}{fsharp}
    // get an Async<'a> from Task<'a>
    let asAsync : Async<'a> = Task.waitForResultAsync someTask

    // synchronously wait (e.g., at boundaries)
    let result : 'a = Task.waitForResult someTask

    // rethrow with original stack trace inside async workflows
    let rethrow (e:exn) = Async.reraise e
\end{minted}

\noindent You can combine these primitives to build clear, reliable pipelines that keep domain logic front-and-center while handling the practical edges of real-world data.

\subsection{Package}

\begin{enumerate}
    
    \item\textbf{Nata.Core} from \href{https://www.nuget.org/packages/Nata.Core/}{NuGet}\footnote{https://www.nuget.org/packages/Nata.Core/}, or using \href{https://fsprojects.github.io/Paket/}{Paket}\footnote{https://fsprojects.github.io/Paket/}:
    \begin{minted}{powershell}
    ./.paket/paket.exe add nuget Nata.Core project MyProject
    \end{minted}
    
    \item\textbf{Reference} and open the Nata.Core library:
    \begin{minted}{fsharp}
    #r "packages/Nata.Core/lib/netstandard2.0/Nata.Core.dll"
    open Nata.Core
    \end{minted}
\end{enumerate}

\subsection{Extensions}

Small, sharp tools that smooth common pipelines: generating identifiers, reshaping tuples, and composing selectors so that domain logic stays readable. The emphasis is on tiny, predictable helpers that slot into larger flows.

\begin{itemize}
\item generate a unique id, or the bytes of one
\begin{minted}{fsharp}
    guid()
    // val it : string = "b2bb73b79ad04871a75a20a478fb3c8c"

    guidBytes()
    // val it : byte [] = [|131uy; 238uy; 246uy; 245uy; 252uy; ...

    // e.g., shuffle a list
    [1..10] |> List.sortBy guid
\end{minted}


\item \mintinline{fsharp}{swap} the parameters of a function, to make pipelining easier
\begin{minted}{fsharp}
    // e.g. look up a long sequence of keys
    let dataSeq = keySeq |> Seq.choose (map |> swap Map.tryFind)
\end{minted}

\item compose functions to \mintinline{fsharp}{mapFst} or \mintinline{fsharp}{mapSnd} a tuple
\begin{minted}{fsharp}
    let unpack : (Event<DataT>*IndexT) -> (DataT*IndexT) =
        mapFst Event.data
\end{minted}

\item \mintinline{fsharp}{filterFst} or \mintinline{fsharp}{filterSnd}

\item \mintinline{fsharp}{chooseFst} or \mintinline{fsharp}{chooseSnd}

\paragraph{Mini examples}
\begin{minted}{fsharp}
    // transform only the index (snd) in a (data * index) tuple
    let bumpIndex : ('a * int) -> ('a * int) =
        mapSnd ((+) 1)

    // filter a list of (key * value) by key only
    let onlyImportant : ('k * 'v) list -> ('k * 'v) list =
        List.filter (filterFst isImportant)

    // choose on the first or second element to conditionally keep tuples
    let keepIfParsedFst : (string * 'b) list -> (int * 'b) list =
        List.choose (chooseFst (fun s ->
            match System.Int32.TryParse s with true, v -> Some v | _ -> None))

    let keepIfParsedSnd : ('a * string) list -> ('a * int) list =
        List.choose (chooseSnd (fun s ->
            match System.Int32.TryParse s with true, v -> Some v | _ -> None))
\end{minted}
\noindent See also \mintinline{fsharp}{Seq.mapFst}/\mintinline{fsharp}{Seq.mapSnd} for sequence variants.

\end{itemize}

\subsubsection{Seq}

\begin{itemize}

\item \mintinline{fsharp}{Seq.tryHead}

\item use \mintinline{fsharp}{Seq.mapFst} or \mintinline{fsharp}{Seq.mapSnd} to transform just the data or index of a seq
\begin{minted}{fsharp}
    let data = events |> Seq.mapFst Event.data
\end{minted}
\noindent See also \mintinline{fsharp}{mapFst}/\mintinline{fsharp}{mapSnd} for tuple variants.

\item similarly use \mintinline{fsharp}{Seq.filterFst}/\mintinline{fsharp}{Seq.filterSnd} or \mintinline{fsharp}{Seq.chooseFst}/\mintinline{fsharp}{Seq.chooseSnd} to select elements by data or index:

\begin{minted}{fsharp}
    events |> Seq.filterFst (Event.data >> isGood)
\end{minted}

\item \mintinline{fsharp}{Seq.log} \mintinline{fsharp}{Seq.logi}

\item \mintinline{fsharp}{Seq.trySkip}

\item \mintinline{fsharp}{Seq.consume} from multiple sequences as data becomes available
\begin{minted}{fsharp}
    [ blockedSeq; blockedSeq; readySeq; blockedSeq ]
    |> Seq.consume
    |> Seq.iter calculate // immediately calculates a value from readySeq
\end{minted}
\emph{Behavior:} pulls from multiple enumerators concurrently, yields values as they arrive, stops when all are exhausted, rethrows the first exception encountered, and attempts to dispose all enumerators.

\item \mintinline{fsharp}{Seq.merge} pulls from left or right based on whichever value comes first
\begin{minted}{fsharp}
    Seq.merge [ 1; 2; 3; 7; 1; ] [ 0; 5; 8; 8 ]
    // val it : seq<int> = seq [0; 1; 2; 3; 5; 7; 1; 8; 8]
\end{minted}

\item \mintinline{fsharp}{Seq.mergeBy} can be used to correctly merge streams of time series data
\begin{minted}{fsharp}
    let dataByTime =
        Seq.mergeBy snd leftEvents rightEvents
        |> Seq.map (fst >> Event.data)
\end{minted}
\emph{Semantics:} inputs should already be ordered by the projection for correct global ordering; when keys are equal, both elements are yielded (left then right).

\item \mintinline{fsharp}{Seq.changes}

\item \mintinline{fsharp}{Seq.changesBy}

\item \mintinline{fsharp}{Seq.delta}

\end{itemize}
\emph{Determinism and cost:} \mintinline{fsharp}{Seq.changes}/\mintinline{fsharp}{Seq.changesBy} and \mintinline{fsharp}{Seq.delta} are single-pass, streaming operations that retain only the last projected value.

\paragraph{Guided examples}
\begin{minted}{fsharp}
    // trace elements in a stream during diagnostics
    events
    |> Seq.log (fun x -> printfn "observed = %A" x)
    |> Seq.iter ignore

    // trace with index when order matters
    events
    |> Seq.logi (fun i x -> printfn "#%d = %A" i x)
    |> Seq.iter ignore

    // skip the first n elements if they represent a warmup period
    events
    |> Seq.trySkip 10
    |> Seq.iter process

    // merge in order by timestamp
    let ordered : seq<Event<'a>> =
        Seq.mergeBy (fun (e,ts) -> ts) left right
        |> Seq.map fst

    // compute point-in-time differences
    let diffs : seq<decimal> =
        values
        |> Seq.delta
        |> Seq.choose (fun (last,next) -> last |> Option.map (fun l -> next - l))
\end{minted}

\paragraph{Small utilities: heads and change detection}
\begin{minted}{fsharp}
    // tryHead returns None on empty sequences
    let firstEvent : Event<'a> option =
        events |> Seq.tryHead

    // changes keeps first element and any element whose projection differs from the previous one
    let uniqueValues : seq<'a> =
        xs |> Seq.changes

    // changesBy allows custom projection (e.g., by key)
    let uniqueByKey : seq<'a> =
        xs |> Seq.changesBy (fun x -> x.Key)
\end{minted}

\subsubsection{Option}

\begin{itemize}
\item provides equivalent functions to \href{https://github.com/fsharp/fsharp/blob/1de369ca6f4564044ff6adee667a5da54f8b7138/src/fsharp/FSharp.Core/option.fs#L20}{\mintinline{fsharp}{Option.defaultValue}} and \href{https://github.com/fsharp/fsharp/blob/1de369ca6f4564044ff6adee667a5da54f8b7138/src/fsharp/FSharp.Core/option.fs#L23}{\mintinline{fsharp}{Option.defaultWith}} from the newer F\# core library

\item \mintinline{fsharp}{Option.whenTrue} will convert a value into an option type of \mintinline{fsharp}{Some} only if the predicate is satisfied, otherwise yielding \mintinline{fsharp}{None}
\begin{minted}{fsharp}
    let big = 3 |> Option.whenTrue (fun x -> x > 10)
\end{minted}

\item similar to the SQL coalesce operator, \mintinline{fsharp}{Option.coalesce} will take the first non-\mintinline{fsharp}{None} value in the pipeline
\begin{minted}{fsharp}
    let maybeThreeOtherwiseFourOtherwiseNone =
        maybeThree
        |> Option.coalesce maybeFour
        |> Option.coalesce maybeNone
\end{minted}

\item \mintinline{fsharp}{Option.coalesceWith} will attempt to fill in \mintinline{fsharp}{None} using a function (similar to \mintinline{fsharp}{Option.defaultWith})
\begin{minted}{fsharp}
    let maybeFourIfNone =
        maybeNone
        |> Option.coalesceWith maybeProduceAnExpensiveFour
\end{minted}

\item \mintinline{fsharp}{Option.tryFunction} will sink any exceptions into \mintinline{fsharp}{None}

\begin{minted}{fsharp}
    input
    |> Option.tryFunction (fun x -> failwith "error to sink"; x)
    //val it : SomeType option = None
\end{minted}

\item split an optional tuple into two separate options using \mintinline{fsharp}{Option.distribute}
\begin{minted}{fsharp}
    let someOne, someTwo =
        Some (1,2)
        |> Option.distribute
    // val someOne : int option = Some 1
    // val someTwo : int option = Some 2
\end{minted}

\item collapse an \mintinline{fsharp}{'a option option} field using \mintinline{fsharp}{Option.join}
\begin{minted}{fsharp}
    Some (Some 3) |> Option.join
    // val it : int option = Some 3
    
    Some None |> Option.join
    // val it : int option = None
    
    None |> Option.join
    // val it : int option = None
\end{minted}

\end{itemize}

\paragraph{Notes and examples}
\begin{minted}{fsharp}
    // prefer the first Some; otherwise fall back
    let chosenUser : User option =
        primaryUser
        |> Option.coalesce backupUser

    // compute a fallback only when needed
    let config : Settings =
        cached
        |> Option.coalesceWith (fun () -> loadFromDisk())
        |> Option.defaultWith (fun () -> defaultSettings())

    // provide a concrete default when both are None
    let threads : int =
        None |> Option.defaultValue 4

    // split and join of nested options
    let a,b = Some (1,2) |> Option.distribute   // Some 1, Some 2
    let flattened : int option = Some (Some 3) |> Option.join  // Some 3
\end{minted}

\noindent When failures must preserve error information, prefer \mintinline{fsharp}{Result}; \mintinline{fsharp}{Option.tryFunction} is best when absence on failure is the intended signal.

\subsubsection{Null}

\begin{itemize}

\item safely convert \mintinline{fsharp}{null} values to \mintinline{fsharp}{option}
\begin{minted}{fsharp}
    nullString
    |> Null.toOption
    // val it : string option = None
\end{minted}

\end{itemize}

\subsubsection{Nullable}

Transform \mintinline{fsharp}{Nullable} values, or exchange them for \mintinline{fsharp}{option}.

\begin{itemize}

\item apply \mintinline{fsharp}{Nullable.map} as you would with \mintinline{fsharp}{Option.map}
\begin{minted}{fsharp}
    Nullable 3
    |> Nullable.map ((+) 2)
    // val it : Nullable<int> = 5
    
    Nullable ()
    |> Nullable.map ((+) 2)
    // val it : Nullable<int> = null
\end{minted}

\item convert a \mintinline{fsharp}{Nullable.toOption} and get the \mintinline{fsharp}{Nullable.ofOption} values
\begin{minted}{fsharp}
    let threeOption =
        Nullable 3
        |> Nullable.toOption
    // val threeOption : Option<int> = Some 3
    
    threeOption
    |> Nullable.ofOption
    // val it : Nullable<int> = 3
\end{minted}

\end{itemize}

\subsubsection{Boolean}

\begin{itemize}
\item \mintinline{fsharp}{Boolean.ofString} / \mintinline{fsharp}{Boolean.toString}
\end{itemize}

\paragraph{Boolean helpers: quick examples}
\begin{minted}{fsharp}
    let featureEnabled : bool option = "true"  |> Boolean.ofString  // Some true
    let asText         : string      = false   |> Boolean.toString  // "False"
\end{minted}

\subsubsection{Decimal}

\begin{itemize}
\item \mintinline{fsharp}{Decimal.between}
\item \mintinline{fsharp}{Decimal.ofString} / \mintinline{fsharp}{Decimal.toString}
\end{itemize}

\subsubsection{Int64}

\begin{itemize}
\item \mintinline{fsharp}{Int64.between}
\item \mintinline{fsharp}{Int64.ofString} / \mintinline{fsharp}{Int64.toString}
\end{itemize}

\subsubsection{Int32}

\begin{itemize}
\item \mintinline{fsharp}{Int32.between}
\item \mintinline{fsharp}{Int32.ofString} / \mintinline{fsharp}{Int32.toString}
\end{itemize}

\paragraph{Numeric helpers: quick examples}
\begin{minted}{fsharp}
    // parse with validation, clamp to a safe range
    let safePercent : int option =
        input
        |> Int32.ofString
        |> Option.map (Int32.between (0, 100))

    // decimal ratios clamped to [0m, 1m]
    let ratio : decimal option =
        s
        |> Decimal.ofString
        |> Option.map (Decimal.between (0m, 1m))

    // 64-bit parsing and clamping
    let maybeId64 : int64 option = "12345" |> Int64.ofString
    let cappedId64 : int64 option = maybeId64 |> Option.map (Int64.between (0L, 10000L))

    // toString helpers for serialization/logging
    let iAsText : string = 42           |> Int32.toString
    let dAsText : string = 12.34m       |> Decimal.toString
    let lAsText : string = 123456789L   |> Int64.toString
\end{minted}

\subsubsection{String}

\begin{itemize}
\item \mintinline{fsharp}{String.replace}
\item \mintinline{fsharp}{String.remove}
\item \mintinline{fsharp}{String.contains}
\item \mintinline{fsharp}{String.containsIgnoreCase}
\item \mintinline{fsharp}{String.split}
\item \mintinline{fsharp}{String.trySubstring}
\item \mintinline{fsharp}{String.tryStartAt}
\end{itemize}

\paragraph{Null-safe string operations}
\begin{minted}{fsharp}
    // case-insensitive search
    let hasHello : bool =
        "Hello, World!" |> String.containsIgnoreCase "hello"

    // safe slicing when indices may be out of bounds
    let middle : string option =
        "abcdef" |> String.trySubstring 2 3   // Some "cde"

    // tolerant splitting for nullable input
    let parts : string list =
        (null:string) |> String.split ','     // []

    // simple edit helpers
    let masked : string = "abc-123-xyz" |> String.remove "-"
    let swapped : string = "color"      |> String.replace "or" "our"  // "colour"

    // contains with null-tolerance
    let hasToken : bool = "a,b,c" |> String.contains "b"

    // safe substring from index to end
    let tail : string option = "prefix-body" |> String.tryStartAt 7   // Some "body"
\end{minted}
\noindent \emph{Null semantics:} \mintinline{fsharp}{String.contains null null} returns true; if either argument is null otherwise, it returns false.

\subsubsection{Async}

\begin{itemize}
\item \mintinline{fsharp}{Async.reraise}
\end{itemize}

\subsubsection{Task}

\begin{itemize}
\item \mintinline{fsharp}{Task.wait}, \mintinline{fsharp}{Task.waitAsync}
\item \mintinline{fsharp}{Task.waitForResult}, \mintinline{fsharp}{Task.waitForResultAsync}
\end{itemize}

\paragraph{Concurrency interop}
\begin{minted}{fsharp}
    // rethrow inside async with original stack trace
    let runSafely (work: Async<'a>) : Async<'a> = async {
        try
            return! work
        with e ->
            Async.reraise e
            return Unchecked.defaultof<'a> // unreachable
    }

    // bridge Task<'T> -> Async<'T>, or wait at well-chosen boundaries
    let fromTask : Async<'a> = Task.waitForResultAsync someTask
    let result  : 'a        = Task.waitForResult someTask

    // wait asynchronously for Task (no result)
    do! Task.waitAsync someUnitTask

    // or synchronously (use sparingly, at process boundaries)
    Task.wait someUnitTask
\end{minted}

\subsection{Codec}

\noindent A codec is a small, composable pair of pure functions used to translate values back and forth between two representations. It captures both directions explicitly:
\begin{minted}{fsharp}
    // A codec is (encode : 'In -> 'Out, decode : 'Out -> 'In)
    type Codec<'In,'Out> = ('In -> 'Out) * ('Out -> 'In)
\end{minted}
This makes codecs pleasant to wire together: you can reverse them when you need the opposite direction, and concatenate them to build multi-step translations that still round-trip.

\subsubsection{Helpers: encoder, decoder, reverse, concatenate}
\begin{itemize}
  \item \mintinline{fsharp}{Codec.encoder} and \mintinline{fsharp}{Codec.decoder} project out the first and second function of a codec. These are convenient when you prefer named accessors over tuple deconstruction.
  \item \mintinline{fsharp}{Codec.reverse} swaps directions, turning a codec \mintinline{fsharp}{'In <-> 'Out} into \mintinline{fsharp}{'Out <-> 'In}.
  \item \mintinline{fsharp}{Codec.concatenate} composes two codecs end-to-end so you can build \mintinline{fsharp}{'A <-> 'C} from \mintinline{fsharp}{'A <-> 'B} and \mintinline{fsharp}{'B <-> 'C}.
\end{itemize}

\paragraph{Guided examples}
\begin{minted}{fsharp}
    open Nata.Core

    // Pull out the encode/decode functions
    let encodeInt, decodeInt = Codec.Int32ToString
    let text : string = encodeInt 42            // "42"
    let back : int    = decodeInt "not-a-number"// 0 (tolerant default)

    // Reverse a codec when you need the opposite direction
    let stringToDecimal : Codec<string, decimal> =
        Codec.reverse Codec.DecimalToString

    let parse : string -> decimal = Codec.encoder stringToDecimal
    let d1 = parse "12.50"    // 12.50m
    let d0 = parse "oops"     // 0m (tolerant default)

    // Concatenate to build multi-step codecs (Int32 <-> String <-> Bytes)
    let Int32ToBytes : Codec<int, byte[]> =
        Codec.Int32ToString
        |> Codec.concatenate Codec.StringToBytes

    let toBytes   : int   -> byte[] = Codec.encoder Int32ToBytes
    let fromBytes : byte[]-> int    = Codec.decoder Int32ToBytes

    let bytes   = toBytes 42
    let value42 = fromBytes bytes    // 42

    // You can also decompose and pipe directly if you prefer
    let textAgain : string =
        42 |> Codec.encoder Codec.Int32ToString

    let safeBool : bool =
        "TRUE" |> Codec.decoder Codec.BooleanToString  // true
\end{minted}

\subsubsection{Built-in codecs}
The following codecs provide practical defaults for everyday work. They are all tolerant of common edge cases and aim to round-trip sensibly.

\paragraph{Identity}
\begin{itemize}
  \item \mintinline{fsharp}{Codec.Identity : Codec<'a,'a>}  the no-op codec.
\end{itemize}
\begin{minted}{fsharp}
    let sameA, sameB = Codec.Identity
    let x = sameA 123   // 123
    let y = sameB 123   // 123
\end{minted}

\paragraph{UTF-8 strings and bytes}
\begin{itemize}
  \item \mintinline{fsharp}{Codec.StringToBytes : Codec<string, byte[]>}
  \item \mintinline{fsharp}{Codec.BytesToString : Codec<byte[], string>} (the reverse)
\end{itemize}
Semantics: UTF-8 encoding. Null-safe by design  null strings behave like empty text, and null byte arrays behave like empty buffers.
\begin{minted}{fsharp}
    let toBytes, toText = Codec.StringToBytes

    let b1 : byte[] = toBytes "hello"  // UTF-8 bytes
    let s1 : string = toText b1        // "hello"

    let emptyFromNullText : byte[] = toBytes null      // [||]
    let emptyTextFromNull : string  = toText null      // ""
\end{minted}

\paragraph{Numbers and booleans (string round-trips)}
Each numeric/boolean codec maps invalid input to a safe default when decoding from string.
\begin{itemize}
  \item \mintinline{fsharp}{Codec.Int32ToString   : Codec<int,    string>}  decode default: \mintinline{fsharp}{0}
  \item \mintinline{fsharp}{Codec.Int64ToString   : Codec<int64,  string>}  decode default: \mintinline{fsharp}{0L}
  \item \mintinline{fsharp}{Codec.DecimalToString : Codec<decimal,string>}  decode default: \mintinline{fsharp}{0m}
  \item \mintinline{fsharp}{Codec.BooleanToString : Codec<bool,   string>}  decode default: \mintinline{fsharp}{false}
\end{itemize}
Reverse variants are provided for convenience:
\begin{itemize}
  \item \mintinline{fsharp}{Codec.StringToInt32    : Codec<string, int>}
  \item \mintinline{fsharp}{Codec.StringToInt64    : Codec<string, int64>}
  \item \mintinline{fsharp}{Codec.StringToDecimal  : Codec<string, decimal>}
  \item \mintinline{fsharp}{Codec.StringToBoolean  : Codec<string, bool>}
\end{itemize}
\begin{minted}{fsharp}
    // Int32
    let toText32, fromText32 = Codec.Int32ToString
    let ok  = fromText32 "123"     // 123
    let bad = fromText32 "oops"    // 0 (default)

    // Boolean
    let toBoolText, fromBoolText = Codec.BooleanToString
    let yes = fromBoolText "true"  // true
    let no  = fromBoolText "nope"  // false (default)

    // Decimal and Int64 similarly
    let toTextDec, fromTextDec = Codec.DecimalToString
    let amt = fromTextDec "9.99"   // 9.99m

    let toText64, fromText64 = Codec.Int64ToString
    let id  = fromText64 "18446744073709551615" // overflowy text -> 0L default
\end{minted}

\subsubsection{Composing to meet I/O boundaries}
Codecs shine at process boundaries: serialize to bytes for storage, reverse for parsing when reading, and keep the round-trip logic centralized.
\begin{minted}{fsharp}
    // Build a codec for decimal <-> bytes via string
    let DecimalToBytes : Codec<decimal, byte[]> =
        Codec.DecimalToString
        |> Codec.concatenate Codec.StringToBytes

    // Use it to persist and recover
    let write : decimal -> byte[] = Codec.encoder DecimalToBytes
    let read  : byte[]  -> decimal = Codec.decoder DecimalToBytes

    let persisted = write 12.34m
    let restored  = read persisted    // 12.34m
\end{minted}

\paragraph{Notes}
\begin{itemize}
  \item Decoding is intentionally forgiving in the built-in codecs (e.g., invalid numeric text falls back to a neutral value). If you need strict parsing, consider validating prior to decode or wrapping with a stricter adapter.
  \item \mintinline{fsharp}{Codec.reverse} and \mintinline{fsharp}{Codec.concatenate} preserve the spirit of reversible transformations while making multi-step encodings ergonomic.
\end{itemize}

\subsection{JsonValue}

\noindent A small interop layer around \mintinline{fsharp}{FSharp.Data.JsonValue} that focuses on:
\begin{itemize}
  \item parsing and safe navigation (\mintinline{fsharp}{tryParse}, \mintinline{fsharp}{tryGet}/\mintinline{fsharp}{get}, \mintinline{fsharp}{properties}/\mintinline{fsharp}{keys}/\mintinline{fsharp}{values})
  \item converting to/from compact text and bytes (\mintinline{fsharp}{toString}/\mintinline{fsharp}{ofString}, \mintinline{fsharp}{toBytes}/\mintinline{fsharp}{ofBytes})
  \item bridging JSON to domain types (\mintinline{fsharp}{toType<'T>}/\mintinline{fsharp}{ofType<'T>}) with pragmatic converters for options, tuples, and discriminated unions
  \item composable codecs for common round-trips
\end{itemize}

\subsubsection{Parse and navigate}

\begin{minted}{fsharp}
    open FSharp.Data
    open Nata.Core.JsonValue

    let text = """{ "name": "Ada", "age": 36, "tags": ["math","code"] }"""

    // tolerant parse: None if invalid JSON
    let parsed : JsonValue option = text |> JsonValue.tryParse

    // required property (throws if missing)
    let name : JsonValue =
        parsed
        |> Option.defaultWith (fun () -> failwith "invalid json")
        |> JsonValue.get "name"

    // optional property
    let nickname : JsonValue option =
        parsed
        |> Option.bind (JsonValue.tryGet "nickname")

    // list structure
    let keys   : string[]    = parsed.Value |> JsonValue.keys
    let values : JsonValue[] = parsed.Value |> JsonValue.values
\end{minted}

\paragraph{Notes}
\begin{itemize}
  \item \mintinline{fsharp}{get} assumes the property exists and will throw if it doesn't; use \mintinline{fsharp}{tryGet} when absence is acceptable.
  \item \mintinline{fsharp}{toString} emits compact JSON (no pretty formatting) to keep byte-wise round-trips stable.
\end{itemize}

\subsubsection{Strings and bytes}

\begin{minted}{fsharp}
    open Nata.Core.JsonValue

    let json : JsonValue = JsonValue.ofString """{ "n": 3 }"""

    // JsonValue <-> string
    let asText : string   = json |> JsonValue.toString
    let back   : JsonValue = asText |> JsonValue.ofString

    // JsonValue <-> bytes (UTF-8)
    let asBytes : byte[]  = json |> JsonValue.toBytes
    let back2   : JsonValue = asBytes |> JsonValue.ofBytes
\end{minted}

\subsubsection{Types and converters}

\noindent You can translate between JSON and domain types via \mintinline{fsharp}{toType<'T>} and \mintinline{fsharp}{ofType<'T>}. Converters are provided so that common F\# shapes serialize naturally:
\begin{itemize}
  \item \textbf{Options} serialize their contained value or null (e.g., \mintinline{fsharp}{Some 3} $\rightarrow$ \mintinline{fsharp}{3}, \mintinline{fsharp}{None} $\rightarrow$ \mintinline{fsharp}{null}).
  \item \textbf{Tuples} serialize as JSON arrays (e.g., \mintinline{fsharp}{(1,"a")} $\rightarrow$ \mintinline{fsharp}{[1,"a"]}).
  \item \textbf{Simple unions (no fields)} serialize as their case name by default. Unions with data appear in a canonical \mintinline{fsharp}{{"Case": "...","Fields":[...]}} form.
\end{itemize}

\begin{minted}{fsharp}
    open Nata.Core.JsonValue

    // simple record round-trip
    type User = { Id:int; Name:string }

    let asUserJson : JsonValue = { Id=1; Name="Ada" } |> JsonValue.ofType
    let userBack   : User      = asUserJson |> JsonValue.toType

    // unions with data use the Case/Fields shape
    type NumberOrText = | Number of int | Text of string

    let sample : NumberOrText = Text "hello"
    let jsonDU : JsonValue = sample |> JsonValue.ofType
    let backDU : NumberOrText = jsonDU |> JsonValue.toType
\end{minted}

\subsubsection{Codecs: compose round-trips}

\noindent The \mintinline{fsharp}{JsonValue.Codec} submodule exposes codecs to assemble end-to-end pipelines:
\begin{itemize}
  \item \mintinline{fsharp}{JsonValueToString} / \mintinline{fsharp}{StringToJsonValue}
  \item \mintinline{fsharp}{JsonValueToBytes}  / \mintinline{fsharp}{BytesToJsonValue}
  \item \mintinline{fsharp}{createTypeToJsonValue<'T>} / \mintinline{fsharp}{createJsonValueToType<'T>}
  \item \mintinline{fsharp}{createTypeToString<'T>} / \mintinline{fsharp}{createStringToType<'T>}
  \item \mintinline{fsharp}{createTypeToBytes<'T>} / \mintinline{fsharp}{createBytesToType<'T>}
\end{itemize}

\paragraph{Guided examples}
\begin{minted}{fsharp}
    open Nata.Core
    open Nata.Core.JsonValue

    // 1) User preferences <-> string
    type UserPreference = { Theme:string; ReceiveEmails:bool }

    let prefToText, prefOfText : Codec<UserPreference, string> =
        JsonValue.Codec.createTypeToString()

    let originalPref = { Theme = "dark"; ReceiveEmails = true }

    let savedText   : string          = originalPref |> Codec.encoder prefToText
    let restoredPref: UserPreference  = savedText     |> Codec.decoder prefToText

    assert (restoredPref = originalPref)

    // 2) Shopping cart line <-> bytes
    type CartLine = { Sku:string; Qty:int; Price:decimal }

    let lineToBytes, lineOfBytes : Codec<CartLine, byte[]> =
        JsonValue.Codec.createTypeToBytes()

    let line    = { Sku="ABC-123"; Qty=2; Price=9.99m }
    let payload : byte[] = line |> Codec.encoder lineToBytes
    let back    : CartLine = payload |> Codec.decoder lineToBytes

    assert (back = line)

    // 3) Small JSON blobs in pipelines
    //    (compact text and UTF-8 bytes)
    let compact : string =
        """{ "id": 42, "name": "Ada" }"""
        |> JsonValue.ofString
        |> JsonValue.toString   // compact, stable

    let blob : byte[] =
        """{ "ok": true }"""
        |> JsonValue.ofString
        |> JsonValue.toBytes

    let asJson : JsonValue = blob |> JsonValue.ofBytes
\end{minted}

\paragraph{Small example JSON for a discriminated union}
\begin{minted}{fsharp}
    // unions without fields become their case name; with fields they use Case/Fields
    type Status = Ok | Error of string

    let asJson : JsonValue = Error "invalid input" |> JsonValue.ofType
    // {
    //   "Case": "Error",
    //   "Fields": [ "invalid input" ]
    // }
\end{minted}

\subsection{DateTime}

\noindent UTC-first helpers for epoch math, tolerant parsing, JSON interop, and composable codecs. The emphasis is on predictable round-trips and clear intent when moving across process and storage boundaries.

\subsubsection{Overview}
\begin{itemize}
  \item Convert dates to and from Unix time:
    \begin{itemize}
      \item \mintinline{fsharp}{toUnixSeconds}/\mintinline{fsharp}{ofUnixSeconds}
      \item \mintinline{fsharp}{toUnixMilliseconds}/\mintinline{fsharp}{ofUnixMilliseconds}
    \end{itemize}
  \item Normalize between time zones:
    \begin{itemize}
      \item \mintinline{fsharp}{toUtc}/\mintinline{fsharp}{toLocal}, \mintinline{fsharp}{ofOffset}
    \end{itemize}
  \item Tolerant parsing:
    \begin{itemize}
      \item \mintinline{fsharp}{ofString : string -> DateTime option}
    \end{itemize}
  \item JSON bridge:
    \begin{itemize}
      \item \mintinline{fsharp}{toJsonValue}/\mintinline{fsharp}{ofJsonValue} using ISO 8601 round-trip format
    \end{itemize}
  \item Resolution helpers to floor timestamps to a boundary:
    \begin{itemize}
      \item \mintinline{fsharp}{Resolution.year}/\mintinline{fsharp}{month}/\mintinline{fsharp}{day}/\mintinline{fsharp}{hour}/\mintinline{fsharp}{minute}/\mintinline{fsharp}{second}/\mintinline{fsharp}{ms}
    \end{itemize}
  \item Codecs for composable round-trips:
    \begin{itemize}
      \item DateTime \(\leftrightarrow\) Unix seconds/milliseconds, JSON, and compact JSON text
    \end{itemize}
\end{itemize}

\subsubsection{Guided examples}

\paragraph{Unix time (seconds and milliseconds)}
Convert to integral time since the Unix epoch and back. Conversions run through UTC to avoid surprises.
\begin{minted}{fsharp}
    open Nata.Core

    let nowUtc : System.DateTime = System.DateTime.UtcNow

    // seconds since 1970-01-01T00:00:00Z
    let s : DateTime.Unix = DateTime.toUnixSeconds nowUtc
    let backFromS : System.DateTime = DateTime.ofUnixSeconds s

    // milliseconds since epoch
    let ms : DateTime.Unix = DateTime.toUnixMilliseconds nowUtc
    let backFromMs : System.DateTime = DateTime.ofUnixMilliseconds ms
\end{minted}
\emph{Semantics:} seconds/milliseconds are measured from the UTC epoch; integer casts use the usual truncation semantics for fractional values.

\paragraph{Offsets and local/UTC conversions}
Bridge from \mintinline{fsharp}{DateTimeOffset}, and normalize explicitly when you cross boundaries where time zones matter.
\begin{minted}{fsharp}
    let fromOffset (dto:System.DateTimeOffset) : System.DateTime =
        dto |> DateTime.ofOffset   // dto.UtcDateTime

    let roundTripLocal (x:System.DateTime) : System.DateTime =
        x |> DateTime.toLocal |> DateTime.toUtc
\end{minted}

\paragraph{Tolerant parsing, JSON interop}
Parse text when its acceptable to fail with \mintinline{fsharp}{None}. Encode as JSON using an ISO 8601 round-trip string.
\begin{minted}{fsharp}
    open FSharp.Data
    open Nata.Core.JsonValue

    let parsed : System.DateTime option =
        "2023-04-05T12:34:56Z" |> DateTime.ofString

    // DateTime <-> JsonValue
    let asJson : JsonValue =
        System.DateTime(2023,4,5,12,34,56,System.DateTimeKind.Utc)
        |> DateTime.toJsonValue

    let back : System.DateTime =
        asJson |> DateTime.ofJsonValue

    // compact JSON text for transport/logging
    let compact : string =
        asJson |> JsonValue.toString   // e.g., "\"2023-04-05T12:34:56.0000000Z\""
\end{minted}
\emph{Notes:} \mintinline{fsharp}{toJsonValue} emits an ISO 8601 round-trip string (format specifier \mintinline{fsharp}{"o"}) inside a JSON string; \mintinline{fsharp}{JsonValue.toString} returns compact JSON (so quotes are included for JSON strings).

\subsubsection{DateTime.Resolution}
Floor timestamps to a chosen boundary while preserving the original \mintinline{fsharp}{DateTimeKind} (UTC or Local).
\begin{minted}{fsharp}
    let sample =
        System.DateTime(2023, 4, 5, 12, 34, 56, 789, System.DateTimeKind.Utc)

    let atYear   = sample |> DateTime.Resolution.year   // 2023-01-01T00:00:00.000Z
    let atMonth  = sample |> DateTime.Resolution.month  // 2023-04-01T00:00:00.000Z
    let atDay    = sample |> DateTime.Resolution.day    // 2023-04-05T00:00:00.000Z
    let atHour   = sample |> DateTime.Resolution.hour   // 2023-04-05T12:00:00.000Z
    let atMinute = sample |> DateTime.Resolution.minute // 2023-04-05T12:34:00.000Z
    let atSecond = sample |> DateTime.Resolution.second // 2023-04-05T12:34:56.000Z
    let atMs     = sample |> DateTime.Resolution.ms     // 2023-04-05T12:34:56.789Z
\end{minted}
\emph{Semantics:} each function zeroes lower-order components (e.g., \mintinline{fsharp}{minute} keeps year/month/day/hour and sets minutes lower parts to zero). These are useful for binning, windowing, and summarization.

\subsubsection{DateTime.Codec}
Composable codecs for common round-trips. These pair naturally with the general \mintinline{fsharp}{Codec} and \mintinline{fsharp}{JsonValue.Codec} helpers elsewhere in this document.
\begin{minted}{fsharp}
    open Nata.Core
    open Nata.Core.JsonValue

    // DateTime <-> Unix seconds
    let toSec, ofSec = DateTime.Codec.DateTimeToUnixSeconds
    let secValue : DateTime.Unix = System.DateTime.UtcNow |> Codec.encoder toSec
    let fromSec  : System.DateTime = secValue |> Codec.decoder toSec

    // DateTime <-> Unix milliseconds
    let toMs, ofMs = DateTime.Codec.DateTimeToUnixMilliseconds

    // DateTime <-> JsonValue
    let toJson, ofJson = DateTime.Codec.DateTimeToJson

    // DateTime <-> compact JSON text
    // (note: this is JSON text of a JSON string value, e.g. "\"...Z\"")
    let toText, ofText = DateTime.Codec.DateTimeToString

    let serialized : string =
        System.DateTime(2023,1,1,0,0,0,System.DateTimeKind.Utc)
        |> Codec.encoder toText

    let restored : System.DateTime =
        serialized |> Codec.decoder toText

    // End-to-end: DateTime <-> bytes (via JSON)
    let DateTimeToBytes : Codec<System.DateTime, byte[]> =
        DateTime.Codec.DateTimeToJson
        |> Codec.concatenate JsonValue.Codec.JsonValueToBytes

    let payload : byte[] =
        System.DateTime.UtcNow |> Codec.encoder DateTimeToBytes

    let roundTripped : System.DateTime =
        payload |> Codec.decoder DateTimeToBytes
\end{minted}
\emph{Notes:} the text/bytes codecs intentionally use compact JSON for consistency with other JSON-based codecs; reverse them when you need the opposite direction, or concatenate with additional codecs to meet I/O boundaries cleanly.

\subsection{Patterns}

\noindent Small, purposeful active patterns make parsing-at-the-boundary feel natural. They turn tolerant conversions into readable matches so that pipelines stay declarative while handling the messy edges of real-world data.

\subsubsection{Overview}
The following partial patterns are available:
\begin{itemize}
  \item \mintinline{fsharp}{( |Nullable|_| ) : System.Nullable<'T> -> 'T option}  bridge from \mintinline{fsharp}{Nullable<'T>} into \mintinline{fsharp}{option}.
  \item \mintinline{fsharp}{( |Boolean|_| ) : string -> bool option}  match text that parses to a boolean.
  \item \mintinline{fsharp}{( |Decimal|_| ) : string -> decimal option}  match text that parses to a decimal.
  \item \mintinline{fsharp}{( |Integer32|_| ) : string -> int option}  match text that parses to Int32.
  \item \mintinline{fsharp}{( |Integer64|_| ) : string -> int64 option}  match text that parses to Int64.
  \item \mintinline{fsharp}{( |DateTime|_| ) : string -> System.DateTime option}  match text that parses to a timestamp.
  \item \mintinline{fsharp}{( |JsonValue|_| ) : string -> JsonValue option}  match text that parses to JSON.
  \item \mintinline{fsharp}{( |AggregateException|_| ) : exn -> exn option}  unwrap an \mintinline{fsharp}{AggregateException} to its inner exception.
  \item \mintinline{fsharp}{( |AbsoluteUri|_| ) : string -> System.Uri option}  match absolute URIs.
  \item \mintinline{fsharp}{( |RelativeUri|_| ) : string -> System.Uri option}  match relative URIs.
  \item \mintinline{fsharp}{( |Uri|_| ) : string -> System.Uri option}  match URIs of either kind.
\end{itemize}

\paragraph{Why patterns?}
At ingestion points (files, queues, sockets, webhooks) you often receive untyped text. Active patterns let you route and normalize that input succinctly:
\begin{minted}{fsharp}
    open Nata.Core

    let handle (line:string) =
        match line with
        | JsonValue json ->
            // structured payload; proceed to domain decode
            json |> JsonValue.toString |> printfn "json=%s"
        | Integer64 id ->
            // numeric id in text form
            printfn "id=%d" id
        | AbsoluteUri uri ->
            // fetch or enqueue work for this resource
            printfn "uri=%O" uri
        | Boolean flag ->
            printfn "flag=%b" flag
        | _ ->
            printfn "unrecognized: %s" line
\end{minted}

\subsubsection{Guided examples}
\paragraph{Batch lines into typed records}
Normalize a CSV-like feed where each field may be missing or malformed; only keep fully-parsed rows.
\begin{minted}{fsharp}
    open Nata.Core

    type Order = { UserId:int64; At:System.DateTime; Amount:decimal }

    let tryOrder (line:string) : Order option =
        match line.Split(',') with
        | [| Integer64 userId; DateTime at; Decimal amount |] ->
            Some { UserId = userId; At = at; Amount = amount }
        | _ -> None

    let parsed : seq<Order> =
        lines |> Seq.choose tryOrder
\end{minted}

\paragraph{Nullable interop (databases, external SDKs)}
Turn \mintinline{fsharp}{Nullable<'T>} into options without ceremony.
\begin{minted}{fsharp}
    open Nata.Core

    let discountOption : decimal option =
        match row.NullableDiscount with
        | Nullable d -> Some d
        | _ -> None
\end{minted}

\paragraph{URIs in routing and partitioning}
Accept both relative and absolute targets, or insist on absolute when necessary.
\begin{minted}{fsharp}
    open Nata.Core

    let route (target:string) =
        match target with
        | AbsoluteUri uri -> sprintf "fetch-remote:%O" uri
        | RelativeUri uri -> sprintf "fetch-local:%O" uri
        | _               -> "drop"

    [ "/inbox/a.json"; "https://example.com/x"; "???"]
    |> List.map route
    // ["fetch-local:/inbox/a.json"; "fetch-remote:https://example.com/x"; "drop"]
\end{minted}

\paragraph{Surface the real error from tasks}
Unwrap \mintinline{fsharp}{AggregateException} so handlers can match on the underlying exception type.
\begin{minted}{fsharp}
    open Nata.Core

    let handleError (e:exn) =
        match e with
        | AggregateException inner ->
            printfn "inner: %s" inner.Message
        | _ ->
            printfn "error: %s" e.Message
\end{minted}

\paragraph{Streaming JSON with tolerant fallbacks}
Allow mixed payloads: compact JSON blob or a single numeric metric as text.
\begin{minted}{fsharp}
    open Nata.Core
    open Nata.Core.JsonValue

    type Payload = Metric of decimal | Doc of JsonValue

    let classify (s:string) : Payload option =
        match s with
        | JsonValue json -> Some (Doc json)
        | Decimal d      -> Some (Metric d)
        | _              -> None

    let results : seq<Payload> =
        inputs |> Seq.choose classify
\end{minted}

\subsubsection{Notes}
\begin{itemize}
  \item All patterns are partial: a non-match simply falls through to the next case.
  \item Numeric, boolean, and date parsing rely on standard \mintinline{fsharp}{TryParse} semantics.
  \item \mintinline{fsharp}{JsonValue} uses a tolerant JSON parser; compact JSON text is convenient for logging and transport.
  \item URI patterns distinguish absolute vs. relative using \mintinline{fsharp}{System.Uri.TryCreate} with the corresponding \mintinline{fsharp}{UriKind}.
  \item Prefer patterns when routing by shape; prefer functions/codecs when you need explicit, composable transformations in a pipeline.
\end{itemize}

\subsection{GZip}

\noindent Lightweight helpers for working with gzip-compressed, line-oriented text. The emphasis is on streaming: you can write an unbounded sequence of lines to a compressed sink, or lazily read large archives without loading them into memory. This is a practical fit for log pipelines, newline-delimited JSON, CSV snapshots, and other append-friendly feeds.

\paragraph{Overview}
\begin{itemize}
  \item Text encoding: UTF-8, one logical line per element (\mintinline{fsharp}{WriteLine}/\mintinline{fsharp}{ReadLine}).
  \item Streaming semantics: \mintinline{fsharp}{read} returns a lazy \mintinline{fsharp}{seq<string>} that decompresses on demand.
  \item Back-pressure friendly: \mintinline{fsharp}{write} flushes per line so long-running producers keep bounded buffers.
  \item Resource ownership: the underlying stream/file is disposed when the gzip layer is disposed (see notes).
\end{itemize}

\subsubsection{GZip.Stream}

\paragraph{Signatures}
\begin{minted}{fsharp}
    open System.IO

    // write a sequence of lines into a target stream as gzip
    val write : target:Stream -> lines:seq<string> -> unit

    // lazily read lines from a gzip source stream
    val read  : source:Stream -> seq<string>
\end{minted}

\paragraph{Write: compress a live feed to a stream}
\begin{minted}{fsharp}
    open System
    open System.IO
    open Nata.Core

    // imagine a long-running sequence (metrics, logs, ids, ...)
    let lines : seq<string> =
        seq {
            for i in 1 .. 1_000_000 do
                yield sprintf "%d,%O" i DateTime.UtcNow
        }

    use target = new MemoryStream() // any writable stream (file, network, memory)
    GZip.Stream.write target lines

    // bytes are gzip-compressed; rewind to inspect
    target.Position <- 0L
    let compressedSize = target.Length
\end{minted}

\paragraph{Read: process large gzip content lazily}
\begin{minted}{fsharp}
    open System
    open System.IO
    open Nata.Core

    // given a gzip payload in memory (or any readable stream),
    // deserialize without loading all lines at once
    let process (source:Stream) =
        for line in GZip.Stream.read source do
            // parse & handle each line
            match line.Split ',' with
            | [| count; timestamp |] -> ()
            | _ -> ()

    // example with MemoryStream
    use buffer = new MemoryStream()
    GZip.Stream.write buffer (seq { for i in 1 .. 1000 -> string i })
    buffer.Position <- 0L
    process buffer
\end{minted}

\paragraph{Newline-delimited JSON (NDJSON) pipelines}
\begin{minted}{fsharp}
    open System.IO
    open Nata.Core
    open Nata.Core.JsonValue

    // write NDJSON to a gzip stream
    let writeJson (target:Stream) (values:seq<'T>) =
        values
        |> Seq.map (JsonValue.ofType >> JsonValue.toString) // compact one-line JSON
        |> GZip.Stream.write target

    // read NDJSON from a gzip stream
    let readJson<'T> (source:Stream) : seq<'T> =
        source
        |> GZip.Stream.read
        |> Seq.choose (JsonValue.tryParse >> Option.map JsonValue.toType<'T>)
\end{minted}

\emph{Semantics and notes:}
\begin{itemize}
  \item The returned sequence from \mintinline{fsharp}{read} is lazy. Enumeration performs on-the-fly decompression; the gzip and underlying streams are disposed when enumeration completes or the enumerator is disposed.
  \item \mintinline{fsharp}{write} flushes after each line to keep buffers small. This favors long-running producers; if you batch large amounts, consider shaping input into larger chunks if throughput is critical.
  \item Resource ownership: the gzip layer closes the underlying stream when done. If you need to keep the underlying stream open for further work, write to or read from a dedicated stream instance.
\end{itemize}

\subsubsection{GZip.File}

\paragraph{Signatures}
\begin{minted}{fsharp}
    open System.IO

    // write lines to a .gz file (creates or overwrites from the beginning)
    val write : target:FileInfo -> lines:seq<string> -> unit

    // lazily read lines from a .gz file
    val read  : source:FileInfo -> seq<string>
\end{minted}

\paragraph{Write: archive a daily feed}
\begin{minted}{fsharp}
    open System
    open System.IO
    open Nata.Core

    let today = DateTime.UtcNow.ToString("yyyyMMdd")
    let file  = FileInfo(sprintf "events-%s.gz" today)

    let events : seq<string> =
        seq {
            yield "started"
            for i in 1 .. 100_000 do yield sprintf "tick=%d" i
            yield "stopped"
        }

    GZip.File.write file events
\end{minted}

\paragraph{Read: stream from disk without loading it all}
\begin{minted}{fsharp}
    open System.IO
    open Nata.Core

    let scan (gz:FileInfo) =
        gz
        |> GZip.File.read
        |> Seq.filter (fun line -> line.Contains "ERROR")
        |> Seq.iter (printfn "error: %s")

    scan (FileInfo "service.log.gz")
\end{minted}

\emph{File behavior and notes:}
\begin{itemize}
  \item Reading is lazy: lines are decompressed as you iterate. This allows you to process multi-GB gzip files with bounded memory.
  \item Writing opens the file for writing from the beginning. If a file already exists and your new compressed output is shorter than the old content, trailing bytes may remain on disk. Prefer writing to a fresh path (e.g., rotate by date/time) or delete the existing file before writing when you need a clean overwrite.
  \item Both \mintinline{fsharp}{write} and \mintinline{fsharp}{read} manage their file streams internally and dispose them when complete.
\end{itemize}

\paragraph{Common scenarios}
\begin{itemize}
  \item Log compaction: persist operational logs as newline-delimited text into daily \mintinline{fsharp}{.gz} files; read them back lazily for reporting.
  \item Data exchange: ship NDJSON snapshots to object storage; downstream jobs stream-decompress and decode line-by-line.
  \item Long-running streams: keep a process emitting metrics where each line is immediately flushed into a rolling \mintinline{fsharp}{.gz} file to bound memory while retaining good compression.
\end{itemize}

\subsection{BloomFilter}

\noindent A Bloom filter is a compact, probabilistic set optimized for fast membership checks. It trades exactness for space and speed: it can yield false positives (``probably seen''), but never false negatives after you add an element. In practice, this is ideal for skip-lists, de-duplication, and pre-filtering high-volume streams.

\paragraph{Overview}
\begin{itemize}
  \item Immutability: operations return a new filter so you can keep prior snapshots when needed.
  \item Union: combine knowledge from multiple filters in O(n) over their bitsets (sizes must match).
  \item Presets: \mintinline{fsharp}{small} ($\sim$2M bits), \mintinline{fsharp}{medium} ($\sim$20M bits), \mintinline{fsharp}{large} ($\sim$200M bits) cover common scales.
  \item Common uses: de-duplicate events, suppress repeated requests, pre-filter expensive lookups, throttle idempotent sinks.
\end{itemize}

\subsubsection{Quick start}
\begin{minted}{fsharp}
    open Nata.Core

    // start with a medium filter by default
    let f0 : BloomFilter = BloomFilter.empty

    // record a few keys (any string works: ids, hashes, URIs, ...)
    let f1 = f0 |> BloomFilter.add "user:ada"
    let f2 = f1 |> BloomFilter.add "user:alan"

    // membership: "probably seen"
    let seenAda   : bool = BloomFilter.contains "user:ada" f2       // true
    let seenGrace : bool = BloomFilter.contains "user:grace" f2     // false (very likely)
\end{minted}

\subsubsection{De-duplicate a live feed}
When processing real-world streams (logs, webhooks, crawls), its common to receive duplicates. A Bloom filter lets you drop repeats without holding the full set in memory.

\begin{minted}{fsharp}
    open Nata.Core

    // keep only the first occurrence of each id
    let dedupe (ids:seq<string>) : seq<string> =
        let folder (f, kept) id =
            if BloomFilter.contains id f then f, kept
            else BloomFilter.add id f, id :: kept
        ids
        |> Seq.fold folder (BloomFilter.small, [])
        |> snd
        |> List.rev
\end{minted}

You can slot this directly after a gzip reader or JSON parser to sanitize upstream feeds before heavier work.

\begin{minted}{fsharp}
    open System.IO
    open Nata.Core
    open Nata.Core.GZip
    open Nata.Core.JsonValue

    // NDJSON in, unique ids out
    let uniqueIdsFromGzip (source:Stream) : seq<string> =
        source
        |> GZip.Stream.read
        |> Seq.choose (JsonValue.tryParse
                       >> Option.bind (JsonValue.tryGet "id")
                       >> Option.map string)
        |> dedupe
\end{minted}

\subsubsection{Union across shards}
If multiple workers or shards maintain their own filters, you can merge them to get the aggregate seen view. All inputs must use the same size preset.

\begin{minted}{fsharp}
    open Nata.Core

    let merged : BloomFilter =
        [ shardA; shardB; shardC ]    // each is a BloomFilter of the same size
        |> List.reduce BloomFilter.union

    let likelySeen = BloomFilter.contains "object:42" merged
\end{minted}

\subsubsection{Composite keys and multi-checks}
Model seen today or seen this user and this session by composing stable string keys. Use \mintinline{fsharp}{containsAll} for conjunction and \mintinline{fsharp}{containsAny} for disjunction.

\begin{minted}{fsharp}
    open Nata.Core

    // key by day + user for a coarse time window
    let keyOf (at:System.DateTime) (user:string) =
        sprintf "%s|%s" (at.ToString "yyyyMMdd") user

    let seenToday (f:BloomFilter) (user:string) (at:System.DateTime) : bool =
        BloomFilter.contains (keyOf at user) f

    // multi-checks: all or any tokens present
    let hasAll  (f:BloomFilter) (tokens:string list) : bool = BloomFilter.containsAll tokens f
    let hasAny  (f:BloomFilter) (tokens:string list) : bool = BloomFilter.containsAny tokens f
\end{minted}

\subsubsection{Rolling windows}
Instead of exact expiry, rotate filters on a cadence (hourly/daily) to bound false positives over time. This works well when combined with upstream time-normalization helpers.

\begin{minted}{fsharp}
    open Nata.Core

    // create a fresh filter at the start of each day; carry on as usual
    let freshFilterFor (at:System.DateTime) : BloomFilter =
        let yyyyMMdd = at.ToString "yyyyMMdd"
        // e.g., use yyyyMMdd as a key to pick/reset the active filter in storage
        BloomFilter.medium
\end{minted}

\paragraph{Notes}
\begin{itemize}
  \item False positives are possible by design; false negatives are not (once added).
  \item If false positives become frequent, choose a larger preset or rotate filters more often.
  \item \mintinline{fsharp}{union} requires filters created with the same size. Mixing sizes is not supported.
  \item Keys are plain strings: prefer stable, canonical encodings (e.g., lowercase IDs, normalized URIs).
\end{itemize}

\subsection{SHA256}

\noindent A compact, fully-immutable implementation of SHA-256 for day-to-day functional work. It favors simple, predictable composition: inputs are plain bytes or UTF-8 text; outputs are either raw digest bytes or lower-case hex strings. There is no internal state, no disposable resources, no hidden I/O  which makes it pleasant to use in pipelines, tests, and reference comparisons.

\paragraph{Signatures}
\begin{minted}{fsharp}
open Nata.Core

// pure digests (no I/O, no mutation)
val hashBytes        : byte[]  -> byte[]  // 32-byte digest
val hash             : byte[]  -> string  // 64-char hex (lowercase)
val hashUTF8Bytes    : string  -> byte[]  // UTF-8 -> digest bytes
val hashUTF8         : string  -> string  // UTF-8 -> hex

// platform-backed comparison helpers (useful for verification)
val referenceBytes     : byte[]  -> byte[]
val reference          : byte[]  -> string
val referenceUTF8Bytes : string  -> byte[]
val referenceUTF8      : string  -> string
\end{minted}

\paragraph{Quick start}
\begin{minted}{fsharp}
open System.Text
open Nata.Core

// hash raw bytes
let digestHex : string =
    "abc" |> Encoding.UTF8.GetBytes |> SHA256.hash

// convenient UTF-8 helpers
let fox : string =
    "The quick brown fox jumps over the lazy dog"
    |> SHA256.hashUTF8
// "d7a8fbb3...c9e592"

// verify against the platform reference
let same : bool =
    let bytes = Encoding.UTF8.GetBytes "hello"
    (SHA256.hash bytes) = (SHA256.reference bytes)
\end{minted}

\paragraph{Why an immutable implementation?}
Immutability keeps the surface area honest: the same input yields the same output every time. With no resources to manageno streams to dispose, no hidden buffersthe functions drop cleanly into folds, maps, and parallel evaluations. This makes them ideal for verification as well: you can place a pure digest beside a platform digest and reason about differences without incidental state. As a bonus, the implementation is a readable reference for the algorithm itself, a portable baseline you can trust when threading hashes through larger pipelines.

\paragraph{Notes}
\begin{itemize}
  \item Hex output is lower-case; digest bytes are exactly 32 bytes.
  \item \mintinline{fsharp}{hashUTF8}/\mintinline{fsharp}{hashUTF8Bytes} always use UTF-8 for text input.
  \item For maximum throughput on large single buffers, prefer the platform implementation; for composable, audit-friendly pipelines and tests, the immutable implementation shines.
  \item Stable input representations matter: prefer canonical JSON (compact, ordered) or explicit binary layouts when the digest must be an id.
\end{itemize}

\clearpage
\appendix
% \listoffigures
\end{document}
